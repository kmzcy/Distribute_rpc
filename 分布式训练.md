

## 项目设计

### 亮点设计

1. 提升代码质量，体现：做好测试，
2. 单元测试的覆盖率，测试用例，开源的测试框架。
3. 上线，部署到服务器上。
4. 有界面，展示项目的运行情况。
5. 给自己的项目压测，开源的压测框架。发现我们的性能瓶颈。修复性能瓶颈。qps/tps提升了多少倍。（制造性能瓶颈，缓存的使用与否？）

### 难点设计

1. 制造难点
2. FGC/CPU飙升的一个问题排查。FGC: 埋藏一个内存泄漏的bug，看博客找一个bug植入系统内，mock一些流量。然后按照排查套路进行排查：DUMP内存，看一下堆中的各个对象的大小，找到内存中是哪个对象过大导致一直占用内存，定位之后如何解决。压测：https://segmentfault.com/a/1190000020211494 
3. jvm(java虚拟机)频繁FGC导致cpu占用过高：https://blog.csdn.net/liaomingwu/article/details/118962901  https://www.cnblogs.com/zjdxr-up/p/15800225.html
4. 并发问题：并发的访问一个不支持并发的集合，伪造？--> 死锁：围绕一个死锁现场进行排查，或，并发集合的问题，因为设计的疏忽没有用并发集合 --> 聊一下并发集合：准备好并发集合的东西，原子类的源码，死锁：写一个死锁？提前准备好死锁的代码。
5. 流量突增：蓄洪，泄洪，制造问题解决问题。

JVM参数设置：https://zhuanlan.zhihu.com/p/117627812

OOM：故障排查：https://blog.csdn.net/qiubboy/article/details/117965200

## 分布式训练

单机多卡拓展到分布式（本质上并没有区别）

单机多卡和分布式训练的区别

1. 数据放在分布式的文件系统中，而不是放在机器本地，所有的机器都能够读取样本。
2. 一般有多个worker，多台机器
3. 多个参数服务器

![image-20230716214855291](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230716214855291.png)

GPU的机器架构：

![image-20230716230745035](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230716230745035.png)

单机的情况下：GPU和GPU之间的带宽是较好的，GPU到CPU的速度会相对降低，而跨机器要通过交换机速度会更进一步降低。因此机器之间的通讯会较慢。所以性能要好，尽量本地之间多通讯

一般来说在GPU里面再做成一个sever

![image-20230717002050433](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230717002050433.png)

在GPU里面再加一层sever尽量通过这层sever对数据进行处理，能够较大的提升整体性能。

样例：样本读进来，分机器和卡拿到自己所需的样本。机器接下来从参数服务器拿到新的模型， 但是我们的模型不能直接复制到每个GPU上面，因为这样速度较慢的通信会发生四次。我们应该先将整个参数拿到主内存中（即运行在GPU间的sever上），再将模型进行分发。每个GPU算自己的梯度后，在本地做allreduce，即所有的GPU数据汇总，相加，在这之后再发回服务器。服务器对收取到的某个梯度求和，更新整个梯度。

![image-20230717003829291](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230717003829291.png)

1. 每个worker（GPU）都同步计算一个批量，成为同步SGD
2. n个GPU，每个GPU每次处理b个样本，同步SGD相当于在单GPU运行批量大小为nb的SGD
3. 理想情况下获得n倍的加速。





![image-20230718143644828](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230718143644828.png)

![image-20230718143800826](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230718143800826.png)

![image-20230718145114451](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230718145114451.png)

对于多机多卡。需要在每个节点上运行如上指令，参数解释：-nnodes：共有多少台机子（节点） node_rank：代表运行在哪个节点上 

![image-20230718151232752](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230718151232752.png)

分布式训练 https://blog.csdn.net/weixin_44966641/article/details/121872773

## 参考资料（将模型部署到spring框架上）

1. https://blog.csdn.net/2201_75499313/article/details/128160480
2. https://blog.csdn.net/qq_33283652/article/details/118574227
3. https://zhuanlan.zhihu.com/p/620192598
4. https://blog.csdn.net/jerry11112/article/details/108166689
5. https://blog.csdn.net/m0_46503651/article/details/106974051?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-106974051-blog-108166689.235%5Ev38%5Epc_relevant_default_base&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-106974051-blog-108166689.235%5Ev38%5Epc_relevant_default_base&utm_relevant_index=1
6. https://blog.csdn.net/m0_46503651/article/details/108555082
7. https://blog.csdn.net/m0_61789994/article/details/130699370?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7EPosition-2-130699370-blog-108166689.235%5Ev38%5Epc_relevant_default_base&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7EPosition-2-130699370-blog-108166689.235%5Ev38%5Epc_relevant_default_base&utm_relevant_index=5

## 思路

flask、tornado（用python的web框架 flask。tornado等搭一个微服务，和java服务之间使用接口调用）

ONNXRuntime（https://zhuanlan.zhihu.com/p/582974246）

分发模型，分布计算梯度， 发回终端进行汇总



远程调用 不同的服务放在不同的机器上spring cloud http+json : 天然的跨平台（满足希望卡平台使用显卡的需求）

负载均衡：订单服务需要商品服务，每一个节点都有商品服务，订单服务可以去任意机器查询，不能使得任意一台服务器太忙，也不能使得任意一台服务器太闲。算法：轮询，最小连接：优先选择连接数最小的，散列：同一用户的请求被分配到同意服务器上。（每个计算节点都有空闲和忙碌之分，同样需要类似的东西去进行调度）

服务注册：a调用b，但是a并不知道b在哪台服务器上有，哪些正常，哪些已经下线，为了解决这个问题，引入注册中心。（注册中心可以用于检测显卡是否可用，当获得一个任务后，会将训练任务分散到可用的显卡上）

配置中心：每一个服务都会有大量的配置，并且每个服务都可能部署在多个机器上，我们经常需要变更配置，让每个服务在配置中心获取自己的配置。配置中心集中的管理微服务的配置。

服务的熔断和降级：服务之间相互依赖防止一个服务不可用时造成的雪崩效应。熔断：当被调用的服务经常失败，达到某个阈值时，启动熔断机制，不再去调用这个服务。服务降级：运维期间使非核心业务停机或简单处理，（熔断可用、降级）

API网关：抽象了服务中需要的公共功能，提供了负载均衡、服务自动熔断、灰度发布、统一认证、限流限控、日志统计等丰富的功能。例子：防止后台一下收到过多的请求。



![image-20230723113235447](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230723113235447.png)

![image-20230723113309647](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230723113309647.png)

## 简易RPC框架：

![image-20230727232444477](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230727232444477.png)

RPC简单的讲就是：客户端调用服务端执行，如上图所示：在服务端，本地调用了一个func函数并传入了一个x的值作为参数，调用这个函数我们期待获得一个返回值。然而我们调用的这个函数并不是在本地执行的。而是通过网络传输的方法告诉服务器我们需要调用func方法，参数是9，在服务端收到这个请求后，服务端会调用在服务端的func函数的实现，如上图所示：这个实现是return x+1。服务器在调用完成后把返回值返回服务器.

在go语言实现的gRPC中，要使用rpc我们首先应该定义一个hello.proto文件，这个文件是接口描述语言（IDL）,这个文件规定了服务器方法的方法名、参数、返回值。客户端和服务端通过接口描述语言就知道他们之间要怎么调用相关的接口了。

服务端代码：收到客户端请求，拿到需要调用的函数（SayHello）+参数（HelloRequest），调用本地的函数实现，将返回值（HelloResponse）返回给客户端

![image-20230729014218811](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230729014218811.png)

上面的代码为服务端的实现接受返回的部分的代码，它接受一个hellowrequest，然后取出其中的 name 与 前面的hellow字符串进行拼接，作为HellowResponse返回给客户端，这说明内容是包装在某个结构中的，也可以说是包中，可以被看作是一种协议，就像是网络传输中的层层包装一样。服务端具体的事情就是监听本地的端口、创建RPC服务、注册服务实现。 监听放到请求，就会自动执行实现部分的代码，并将返回值包装起来返回给客户端。

客户端代码：调用函数（SayHello），传入参数（HelloRequest），获得返回值（HelloResponse）



总结：

proto文件（IDL）定义方法、参数、返回值，使用工具直接生成go可以用的库。

Server：创建**grpcServer对象**，注册服务（也就是自己定义的方法，针对proto文件方法的实现），**启动服务器**。

Client：创建**grpcClient对象（给出服务ip+port地址）**，用grpcClient对象调用服务（也就是调用proto文件里面声明的方法），然后打印返回的结果。



java:

框架：

1. 接口文件，定义了方法名、参数、返回值，供客户端和服务端使用
2. RPC框架，让客户端和服务端可以使用框架，达到**本地调用，远端执行**的目的

测试：

1. 写一个TestServer可执行程序，注册方法的实现后，使用rpcServer进行监听并处理rpc调用
2. 写一个TestClient可执行程序，使用rpcClient进行发起rpc调用，并打印rpc调用结果

![image-20230727235252923](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230727235252923.png)

try后接括号：**从java1.7版本开始,支持使用try后面跟随（）括号管理释放资源,前提是这些可关闭的资源必须实现 java.lang.AutoCloseable 接口。**这些资源在执行完try-catch后进行.

![image-20230728233740633](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230728233740633.png)



问题：如何在客户端本地调用了相关的方法后，使得远端调用看起来就像本地调用一样，整个通知的流程是怎么走的？

文件的结构如上图：main里面是源代码，test里面是测试用例

core：框架的核心代码

### 客户端实现（动态代理）

客户端方面，客户端本地只有IDL.Hello中的内容，没有方法的具体实现，也就是说要调用一个没有实现的接口，显然，我们使用Java反射的动态代理特性，实例化一个接口，将调用接口方法“代理”给InvocationHandler中的invoke来执行，在Invoke中获取到接口名、方法名等包装成Rpc协议，发送给服务端，然后等待服务端返回。

IDL: 相当于接口描述语言，Hellowservice中定义的是服务器端提供的服务，以一个接口的方式呈现，服务端实现这些接口，客户端只管调用这些接口。HellowResponse是服务器返回的类，HellowRequest是客户端请求的类，Hellowservice中的两个方法均应该返回HellowResponse类，这三个文件规定了客户端和服务器端之间交换信息的格式，因此对于两端都应该是可见的。这个是属于rpc协议中body的内容。

core.rpc_protocol 中的两个文件则规定了rpc请求报文和返回报文的格式，这里都是一个head加上body，再明确一遍，body中装的就是我们之前规定的回应对象和请求对象，以及相关信息，这些被封装为一个新的对象，它在codec中被定义。

codec中则是存放的是body对象

![image-20230729023433545](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230729023433545.png)

请求请求的是方法，因此要有方法信息

返回返回的是参数，因此有一个参数就只返回一个object就行

IDL里面的东西其实就在object里面

![image-20230729023400661](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230729023400661.png)

![image-20230729140343827](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230729140343827.png)

我们可以看到：通过反射制造的helloService对象 hellowservice 其调用hello 方法时传入的就是hellorequest，而接收到的就是helloresponce，hellow（hi）方法本身是没有实现的，或者说HelloService 中的每个方法都没有实现。调用他们都会转移到我们的 procy代理类的方法，而代理类实际做的事情就是把要传的方法，传入的参数告诉服务器，并从服务器取回返回值。

### 服务端实现（反射调用）

服务端方面，本地需要实现接口的方法，然后在启动监听网络之前注册所有的接口，当消息到来的时候，根据RpcRequestBody中的接口名拿到接口对象，然后用反射的方式调用即可，将调用结果包装成RpcResponse，发送给客户端。

其他的RPC参考：

https://juejin.cn/post/6992867064952127524

https://www.cnblogs.com/chenchuxin/category/2010813.html

AtomicInteger: https://blog.csdn.net/fanrenxiang/article/details/80623884 / https://zhuanlan.zhihu.com/p/87141904 / 

线程池：https://blog.csdn.net/qq_40093255/article/details/116990431

## 分布式系统

我认为整体上来讲要做的东西就是一个分布式系统，那学习分布式系统有助于设置一些问题然后解决相关问题，使得整个项目更有层次性。显得更加真实。但是目前时间不够。因此我们的规划是：首先先看完java guide中rpc相关的部分补足一下项目。

整个系统可以被分为两个阶段的实现目标，第一个阶段：简单的调用深度学习服务 + 系统中的每个机器都能够拥有完整的模型，仅仅传递梯度，在请求服务的主机上加和梯度，更新模型，最后将模型分配到每个主机上进行下一步训练。

每个节点开始运行时会向注册中心注册服务，即将自己的地址信息（ip，端口以及服务等组合信息）上报给注册中心注册中心负责将地址信息保存起来。这就是注册服务。注册服务能够帮助用户自动发现服务，同时提供服务的服务器如果出现问题，也可以进行自动下线，不需要一个一个的维护配置文件。

![image-20230816164003509](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230816164003509.png)

![image-20230816164241251](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230816164241251.png)

### 注册中心的选择

为什么选择zooKeeper作为注册中心：根据CAP理论，分布式架构需要满足三种条件：一致性：所有节点在同一时间具有相同的数据。可用性：保证每个请求都能够获得响应，分割容忍：系统中的任意信息丢失或失败都不会影响系统的正常运作。

- 如果C是第一需求的话，那么会影响A的性能，因为要数据同步，不然请求结果会有差异，但是数据同步会消耗时间，期间可用性就会降低。
- 如果A是第一需求，那么只要有一个服务在，就能正常接受请求，但是对于返回结果变不能保证，原因是，在分布式部署的时候，数据一致的过程不可能想切线路那么快。
- 再如果，同时满足一致性和可用性，那么分区容错就很难保证了，也就是单点，也是分布式的基本核心。

我认为我这个系统更重要的应该是C和P，即保证一致性和分割容忍性，一致性主要在于分割训练需要同步目前模型的信息。

“作为一个分布式协同服务，ZooKeeper非常好，但是对于Service发现服务来说就不合适了，因为对于Service发现服务来说就算是返回了包含不实的信息的结果也比什么都不返回要好。” 这部分是一篇文章中作为ZooKeeper的缺点提出的，我们的系统恰恰相反，每个主机作为训练段能够提供的服务都是相同的，不需要我们容忍注册中心返回的是几分钟以前的注册信息。**Zookeeper的核心算法是ZAB，所有设计都是为了强一致性**。这个对于分布式协调系统，完全没没有毛病，我们的系统本质上讲就是一个分布式协调系统。(分布式协调技术主要用来解决分布式环境当中的多个进程之间的同步控制，让他们有序的去访问某种临界资源，防止造成脏数据的后果)

注册中心的选择：https://mp.weixin.qq.com/s?__biz=Mzg3OTU5NzQ1Mw==&mid=2247486918&idx=1&sn=5651cd0b4b9c8e68bcfa55c00c0950d6&chksm=cf034f24f874c632511684057337a744c54702543ec3690aa06dbf4bbaf980b2828f52276c9b&scene=21#wechat_redirect

### Paxos与Raft（优化项）

解决的是在分布式系统中，整个调用链中，我们所有服务的数据处理要么都成功要么都失败，即所有服务的 **原子性问题** 。

ZooKeeper中已经对相关的东西进行了实现，用于管理zookeeper服务集群，跟我们的注册中心没有关系，如果我们需要这个得自己实现。

| **角色** |                           **说明**                           |
| :------: | :----------------------------------------------------------: |
|  Leader  | 为客户端提供读和写的服务，负责投票的发起和决议，更新系统状态。 |
| Follower | 为客户端提供读服务，如果是写服务则转发给 Leader。参与选举过程中的投票。 |
| Observer | 为客户端提供读服务，如果是写服务则转发给 Leader。不参与选举过程中的投票，也不参与“过半写成功”策略。在不影响写性能的情况下提升集群的读性能。此角色于 ZooKeeper3.3 系列新增的角色。 |

**选举结束后的流程**

某节点超过半数投票先当选准leader，发现阶段：每个follower 向准leader 同步 followers 最近接收的事务提议, 同步阶段：leader整理同步上一阶段收到的事务提议。最后是广播阶段：正式对外提供事务服务，并且 leader 可以进行消息广播

**领袖有任期吗？领袖的责任是什么？选举定时器怎么实现？如何确定领袖的身份，即领袖如何履行自己的职责？**

复制状态机的基本思想是一个分布式的状态机，系统由多个复制单元组成，每个复制单元均是一个状态机，它的状态保存在操作日志中。状态机的操作根据日志进行变化。服务器上的一致性模块负责接收外部命令，然后追加到自己的操作日志中，它与其他服务器上的一致性模块进行通信，以保证每一个服务器上的操作日志最终都以相同的顺序包含相同的指令。一旦指令被正确复制，那么每一个服务器的状态机都将按照操作日志的顺序来处理它们，然后将输出结果返回给客户端。这样可以保证每个服务器所执行的指令和顺序都是相同的。（可以理解为平行加速任务）

数据同步流程，借鉴了“复制状态机”的思想，都是先“提交”，再“应用”。

当Client发起数据更新请求，请求会先到领袖节点C，节点C会更新日志数据，然后通知群众节点也更新日志，当群众节点更新日志成功后，会返回成功通知给领袖C，至此完成了“提交”操作；

当领袖C收到通知后，会更新本地数据，并通知群众也更新本地数据，同时会返回成功通知给Client，至此完成了“应用”操作，如果后续Client又有新的数据更新操作，会重复上述流程。

“提交”更新日志，“应用”更新数据。

**过半机制是如何防止脑裂现象产生的？**

ZooKeeper 的过半机制导致不可能产生 2 个 leader，因为少于等于一半是不可能产生 leader 的，这就使得不论机房的机器如何分配都不可能发生脑裂。

**在我们的系统之中**

对于同步式锁的一些设想：为什么要加锁，每个服务器都会读取新的模型参数，在读取新的模型参数的时候模型参数不能进行修改，服务器的训练速度不统一，我们需要保证应该在一个batch中的操作统一在一个batch中。

raft协议可以用来实现我们的设想：把程序分发到多台机子上，这些机子自己构成一个集群，通过raft协议选取一个注册中心，运行注册中心的相关职责，这样不需要一个固定的注册中心，做到轻量的即插即用。

zookeeper 使用docker安装，补充docker常见命令：https://cloud.tencent.com/developer/article/1891400

### 序列化以及序列化协议选择

序列化：对象转化二进制字节流。反序列化：二进制字节流转化为对象。

对象在网络中传播需要先进行序列化然后进行反序列化

对象存储到文件中需要先进行序列化然后读取时进行反序列化

**序列化的主要目的是通过网络传输对象或者说是将对象存储到文件系统、数据库、内存中**

java本身自带序列化方式，这种方式只需要类实现Serializabel接口即可，通过查看源代码我们可以发现java自带的Hashtable类也可以进行序列化，其中有字段：*serialVersionUID* 这个字段为私有的静态final long 型变量，在反序列化时会进行检查，检查反序列化的对象内的和类内的是否一致，静态变量本身不会序列化，这个序列化只是表象。

自带的序列化本身存在几个问题

1. 不支持跨语言调用
2. 性能较差
3. 反序列化漏洞

序列化我们选取kryo来对对象进行序列化，kryo的性能要远高于java本身自带的序列化方法。

kryo本身线程不安全，因此我们需要使用ThreadLocal来对kyro对象进行处理。

**ThreadLocal的api是这样的：**

![ ](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\1o4rr4e01f.png)

每个Thread维护一个 ThreadLocalMap映射表，这个映射表的key是 ThreadLocal实例本身，value是真正需要存储的Object。ThreadLocalMap本身是定义在ThreadLocal中的一个内部类，map中存储的元素为entry

```java
static class Entry extends WeakReference<ThreadLocal<?>> {
            /** The value associated with this ThreadLocal. */
            Object value;

            Entry(ThreadLocal<?> k, Object v) {
                super(k);
                value = v;
            }
        }
```

key被设置成弱引用主要是因为ThreadlocalMap是和线程绑定在一起的，如果这样线程没有被销毁，而我们又已经不会再某个threadlocal引用，那么key-value的键值对就会一直在map中存在，这对于程序来说，就出现了内存泄漏。

为了避免这种情况，只要将key设置为弱引用，那么当发生GC的时候，就会自动将弱引用给清理掉，也就是说：假如某个用户A执行方法时产生了一份threadlocalA，然后在很长一段时间都用不到threadlocalA时，作为弱引用，它会在下次垃圾回收时被清理掉。

### **ThreadLocalMap的源码实现** 

![image-20230825175739066](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230825175739066.png)

https://cloud.tencent.com/developer/article/1549484

关于弱引用，还有一个有意思的东西：

```java
public static void main(String[] args) throws Exception {
        Map<WeakReference<Integer>, WeakReference<Integer>> map = new HashMap<>(8);
        // 注意这里~
        WeakReference<Integer> key = new WeakReference<>(1);
        WeakReference<Integer> value = new WeakReference<>(127); //改成128就会被GC回收掉
        map.put(key,value);
        System.out.println("put success");
        Thread.sleep(1000);
        System.gc();
        System.out.println("get " + map.get(key).get());
    }
```

为什么**-128 ~ 127之间**GC不会发生作用呢，肯定是因为存在一个强引用，那这个强引用在哪呢？因为Integer类中存在一个私有的静态类：IntegerCache，它其实是一个Integer类型的数组，数组存贮值为-128~127之间的Integer对象。当我们调用`valueOf`方法（自动装箱时）创建Integer对象时，首先查看数值i是否在-128~127之间，如果在，就返回**IntegerCache.cache中存储的对象**，如果**不在，就新创建一个对象**，然后返回。在上面的代码中值为-128-127之间时，其实在Integer类中存在它的强引用。

Thread local 源码解析：

`ThreadLocal`的实现是这样的：每个`Thread` 维护一个 `ThreadLocalMap` 映射表，这个映射表的 `key`是 `ThreadLocal` 实例本身，`value` 是真正需要存储的 `Object`。

也就是说 `ThreadLocal` 本身并不存储值，它只是作为一个 `key` 来让线程从 `ThreadLocalMap` 获取 `value`。值得注意的是图中的虚线，表示 `ThreadLocalMap` 是使用 `ThreadLocal` 的弱引用作为 `Key`的，弱引用的对象在 GC 时会被回收。

`ThreadLocalMap`使用`ThreadLocal`的弱引用作为`key`，如果一个`ThreadLocal`没有外部强引用来引用它，那么系统 `GC `的时候，这个`ThreadLocal`势必会被回收，这样一来，`ThreadLocalMap`中就会出现`key`为`null`的`Entry`，就没有办法访问这些`key`为`null`的`Entry`的`value`，如果当前线程再迟迟不结束的话，这些`key`为`null`的`Entry`的`value`就会一直存在一条强引用链：`Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value`永远无法回收，造成内存泄漏。

为了防止出现这一问题，我们应每次使用完`ThreadLocal`，都调用它的`remove()`方法，清除数据。

回到kryo，简单的使用kyro的方法如下：

```java
public class KryoSerializer implements Serializer {
    /**
     * 每个thread都拥有一个自己的kryo，保证其线程安全性。
     */
    private final ThreadLocal<Kryo> kryoThreadLocal = ThreadLocal.withInitial(() -> {
        Kryo kryo = new Kryo();
        kryo.register(RpcRequest.class);
        kryo.register(RpcResponse.class);
        return kryo;
    });

    @Override
    public byte[] serialize(Object obj) {
        try(ByteArrayOutputStream byteArrayInputStream = new ByteArrayOutputStream();
            Output output = new Output(byteArrayInputStream);)
        {
            Kryo kryo = kryoThreadLocal.get();
            kryo.writeObject(output, obj);
            kryoThreadLocal.remove();
            return output.toBytes();

        }catch (Exception e){
            e.printStackTrace();
            throw new RuntimeException("serialize exception");
        }
    }

    @Override
    public <T> T deserialize(byte[] bytes, Class<T> clazz) {
        try (ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(bytes);
             Input input = new Input(byteArrayInputStream))
        {
            Kryo kryo = kryoThreadLocal.get();
            // byte->Object:从byte数组中反序列化出对对象
            Object o = kryo.readObject(input, clazz);
            kryoThreadLocal.remove();
            return clazz.cast(o);

        } catch (Exception e) {
            e.printStackTrace();
            throw new RuntimeException("deserialize exception");
        }
    }

}
```

### 注册中心

前半段是对参考项目的使用注册中心的部分进行解析，学习参考项目是如何使用注册中心的

```java
public class SocketServerMain {
    public static void main(String[] args) {
        // 在服务器端能够访问到服务的实现，new一个服务
        HelloService helloService = new HelloServiceImpl();
        // 新建一个服务器对象，服务器对象中包含两个功能：注册服务：持有注册中心对象，使用线程池监听socket连接
        SocketRpcServer socketRpcServer = new SocketRpcServer();
        // 构建service的配置类
        RpcServiceConfig rpcServiceConfig = new RpcServiceConfig();
        // 将实际对象提供给配置类
        rpcServiceConfig.setService(helloService);
        // 注册服务
        socketRpcServer.registerService(rpcServiceConfig);
        // 服务器启动
        socketRpcServer.start();
    }
}
```

服务器对象：

```java
public class SocketRpcServer {

    private final ExecutorService threadPool;
    private final ServiceProvider serviceProvider;


    public SocketRpcServer() {
        // 构造器中初始化一个线程池，这个线程池使用自己的方式进行构建
        threadPool = ThreadPoolFactoryUtil.createCustomThreadPoolIfAbsent("socket-server-rpc-pool");
        
        // 通过单例模式获取注册中心的对象
        serviceProvider = SingletonFactory.getInstance(ZkServiceProviderImpl.class);
    }

    public void registerService(RpcServiceConfig rpcServiceConfig) {
        // 将包含服务对象的配置类注册到注册中心，等于说注册中心持有一个服务的实现类
        serviceProvider.publishService(rpcServiceConfig);
    }

    public void start() {
        // 启动一个socketserver
        try (ServerSocket server = new ServerSocket()) {
            String host = InetAddress.getLocalHost().getHostAddress();
			
            server.bind(new InetSocketAddress(host, PORT));
            // ?
            CustomShutdownHook.getCustomShutdownHook().clearAll();
            Socket socket;
            while ((socket = server.accept()) != null) {
                log.info("client connected [{}]", socket.getInetAddress());
                // SocketRpcRequestHandlerRunnable即线程内运行的东西
                threadPool.execute(new SocketRpcRequestHandlerRunnable(socket));
            }
            threadPool.shutdown();
        } catch (IOException e) {
            log.error("occur IOException:", e);
        }
    }
}
```

线程内部的代码：

```java
public class SocketRpcRequestHandlerRunnable implements Runnable {
    private final Socket socket;
    private final RpcRequestHandler rpcRequestHandler;


    public SocketRpcRequestHandlerRunnable(Socket socket) {
        // 线程获取socket连接的对象
        this.socket = socket;
        // 线程获取处理服务的方法
        this.rpcRequestHandler = SingletonFactory.getInstance(RpcRequestHandler.class);
    }

    @Override
    public void run() {
        log.info("server handle message from client by thread: [{}]", Thread.currentThread().getName());
        try (ObjectInputStream objectInputStream = new ObjectInputStream(socket.getInputStream());
             ObjectOutputStream objectOutputStream = new ObjectOutputStream(socket.getOutputStream())) {
            // 从socket中读取到服务请求对象
            RpcRequest rpcRequest = (RpcRequest) objectInputStream.readObject();
            
            // 对服务请求对象进行处理
            Object result = rpcRequestHandler.handle(rpcRequest);
            // 将结果写回
            objectOutputStream.writeObject(RpcResponse.success(result, rpcRequest.getRequestId()));
            objectOutputStream.flush();
        } catch (IOException | ClassNotFoundException e) {
            log.error("occur exception:", e);
        }
    }

}
```

处理请求对象的方法：

```java
public class RpcRequestHandler {
    private final ServiceProvider serviceProvider;

    public RpcRequestHandler() {
        serviceProvider = SingletonFactory.getInstance(ZkServiceProviderImpl.class);
    }

    /**
     * Processing rpcRequest: call the corresponding method, and then return the method
     */
    public Object handle(RpcRequest rpcRequest) {
        // 从注册中心获取到提供服务的对象
        Object service = serviceProvider.getService(rpcRequest.getRpcServiceName());
        // 将请求服务的对象和提供服务的对象同时传入以反射机制为基础构建的处理方法中
        return invokeTargetMethod(rpcRequest, service);
    }

    /**
     * get method execution results
     *
     * @param rpcRequest client request
     * @param service    service object
     * @return the result of the target method execution
     */
    private Object invokeTargetMethod(RpcRequest rpcRequest, Object service) {
        Object result;
        try {
            // 反射机制调用方法
            Method method = service.getClass().getMethod(rpcRequest.getMethodName(), rpcRequest.getParamTypes());
            result = method.invoke(service, rpcRequest.getParameters());
            // 日志更新
            log.info("service:[{}] successful invoke method:[{}]", rpcRequest.getInterfaceName(), rpcRequest.getMethodName());
        } catch (NoSuchMethodException | IllegalArgumentException | InvocationTargetException | IllegalAccessException e) {
            throw new RpcException(e.getMessage(), e);
        }
        return result;
    }
}
```

跟注册中心通信了吗？

通信了，那个对象是注册中心客户端，但是通信是我们写的zookeeper客户端和zookeeper服务进行通信了，如果需要多余的业务逻辑，这些业务逻辑也是在本地实现的。

zookeeper:

采用层次化多叉树结构存储存储数据，每个节点上都可以存储数据，节点分为四类：持久节点，临时节点，持久顺序节点，临时顺序节点。

节点的信息通过stat存储，节点的数据通过data进行存储，如下为使用get查询到是节点的stat信息，以及他们分别代表什么：

![image-20230823174427702](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230823174427702.png)

三个版本信息：

- **dataVersion**：当前 znode 节点的版本号
- **cversion**：当前 znode 子节点的版本
- **aclVersion**：当前 znode 的 ACL 的版本。

ACL权限：ZooKeeper 采用 ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制

Session 可以看作是 ZooKeeper 服务器与客户端的之间的一个 TCP 长连接，通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向 ZooKeeper 服务器发送请求并接受响应，同时还能够**通过该连接接收来自服务器的 Watcher 事件通知**（是否存在访问传输数据的情况）。

sessionTimeout代表会话的超时时间，用于设定连接断开后会话多长时间过期。

session建立时服务端首先会为每个客户端都分配一个 `sessionID`。

为了保证高可用，最好是以集群形态来部署 ZooKeeper，ZooKeeper自身通过多台服务器提供服务，每一台服务器上的信息都是相同的，这些集群通过Raft协议进行管理，并且每台服务器之间都互相保持着通信。集群间通过 ZAB 协议（ZooKeeper Atomic Broadcast）来保持数据的一致性。

之前的项目并没有建立临时节点，在服务器端设置一个关闭钩子，当服务器挂掉的时候就会直接把建立的永久节点删除，但是存在问题，如果服务器不是正常关闭的，直接发生了断网，那永久节点还是没办法删掉。

当curator建立与zookeeper建立连接后，会自动和服务器维持一个心跳机制，用于维持session，这个session会一直维持，不会自动消失除非发生什么额外的情况。同时当服务器端无法连接时，curator默认的策略为不断重复直到连上为止，另外我们还可以为`curatorFramework`（客户端）建立一个监听器，当连接状态发生变化后，做出一定的自定义的反应：

创建连接：

```java
CuratorFramework client;

public void init() {
        RetryPolicy retryPolicy = new ExponentialBackoffRetry(baseSleepTimeMs, maxRetries);
        client = CuratorFrameworkFactory.builder() 
            .connectString(zookeeperServer)
            .retryPolicy(retryPolicy)
            .sessionTimeoutMs(sessionTimeoutMs)
            .connectionTimeoutMs(connectionTimeoutMs)
            .build();
    
        client.start();
    }
```

监听器在客户端上的注册：

```java
public void register() {
        try {
            String rootPath = "/services";
            String hostAddress = InetAddress.getLocalHost().getHostAddress();
            String serviceInstance = "/prometheus" + "-" +  hostAddress + "-";
            String path = rootPath + serviceInstance;
            // 新建监听器
            SessionConnectionListener sessionConnectionListener = new SessionConnectionListener(path, "");
            // 将监听器注册到客户端上
            client.getConnectionStateListenable().addListener(sessionConnectionListener);
            // 创建序列化的临时节点
            client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path);
        } catch (Exception e) {
            logger.error("注册出错", e);
        }
    }
```

监听器部分的代码：

```java
package com.xiaoju.dqa.prometheus.client.zookeeper;

import org.apache.curator.framework.CuratorFramework;
import org.apache.curator.framework.state.ConnectionState;
import org.apache.curator.framework.state.ConnectionStateListener;
import org.apache.zookeeper.CreateMode;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class SessionConnectionListener implements ConnectionStateListener {
    private final Logger logger = LoggerFactory.getLogger(this.getClass());

    private String path;
    private String data;

    public SessionConnectionListener(String path, String data) {
        this.path = path;
        this.data = data;
    }

    @Override
    public void stateChanged(CuratorFramework curatorFramework, ConnectionState connectionState){
        if(connectionState == ConnectionState.LOST){
            logger.error("[负载均衡失败]zk session超时");
            while(true){
                try {
                    if(curatorFramework.getZookeeperClient().blockUntilConnectedOrTimedOut()){
                        curatorFramework.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path, data.getBytes("UTF-8"));
                        logger.info("[负载均衡修复]重连zk成功");
                        break;
                    }
                } catch (InterruptedException e) {
                    break;
                } catch (Exception e){

                }
            }
        }
    }
}
```

为什么要重连：

 在session当中，client随机与其中一个zk provider建立的链接，并且互发心跳heartbeat。zk集群负责管理这个session，并且在所有的provider上维护这个session的信息，包括这个session中定义的临时数据和监视点watcher。

如果再网络不佳或者zk集群中某一台provider挂掉的情况下，有可能出现connection loss的情况，例如client和zk provider1连接断开，这时候client不需要任何的操作(zookeeper api已经给我们做好了)，只需要等待client与其他provider重新连接即可。这个过程可能导致两个结果：

**1）在session timeout之内连接成功**

这个时候client成功切换到连接另一个provider例如是provider2，由于zk在所有的provider上同步了session相关的数据，此时可以认为无缝迁移了。

**2）在session timeout之内没有重新连接**

这就是session expire的情况，这时候zookeeper集群会任务会话已经结束，并清除和这个session有关的所有数据，包括临时节点和注册的监视点Watcher。

在session超时之后，如果client重新连接上了zookeeper集群，很不幸，zookeeper会发出session expired异常，且不会重建session，也就是不会重建临时数据和watcher。



通过Curator使用zookeeper

引入依赖：

```xml
<dependency>
    <groupId>org.apache.curator</groupId>
    <artifactId>curator-framework</artifactId>
    <version>2.12.0</version>
</dependency>
<dependency>
    <groupId>org.apache.curator</groupId>
    <artifactId>curator-recipes</artifactId>
    <version>2.12.0</version>
</dependency>
```

创建客户端，zookeeper将通过客户端进行连接，主要有两种方式对客户端进行创建：静态方式和Fluent方式（builder），静态方式如下：

```java
ExponentialBackoffRetry retry = new ExponentialBackoffRetry(1000, 3);
CuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(connectionStr,5000,5000, retry);
```

其中一共有四个主要参数：

![image-20230825153619143](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230825153619143.png)

Fluent风格的Api创建客户端

```java
RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);
CuratorFramework client = CuratorFrameworkFactory.builder()
                        .connectString(connectionInfo)
                        .sessionTimeoutMs(5000)
                        .connectionTimeoutMs(5000)
                        .retryPolicy(retryPolicy)
                        .build();
```

以上的四个参数的含义与静态方法中的含义相同。

创建包含隔离命名空间的客户端：为了实现不同的zookeeper业务之间的隔离，我们可以为每个客户端指定命名空间，即根目录。例如（下面的例子）当客户端指定了独立命名空间为“/base”，那么该客户端对Zookeeper上的数据节点的操作都是基于该目录进行的。通过设置Chroot可以将客户端应用与Zookeeper服务端的一课子树相对应：

```java
RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);
        CuratorFramework client =
        CuratorFrameworkFactory.builder()
                .connectString(connectionInfo)
                .sessionTimeoutMs(5000)
                .connectionTimeoutMs(5000)
                .retryPolicy(retryPolicy)
                .namespace("base") // 这里
                .build();
```

创建完成后需要使用start()方法启动客户端，要不然连不上。

创建节点：如之前所述，zookeeper中的节点一共分为4类，临时节点、永久节点、顺序临时节点、顺序永久节点。

```java
// 创建一个节点，初始内容为空, 如果没有设置节点属性，节点创建模式默认为持久化节点，内容默认为空。
client.create().forPath("/path");

// 创建一个节点，附带初始化内容
client.create().forPath("/path2", "test1".getBytes());

// 创建一个节点，指定创建模式（临时节点），内容为空
client.create().withMode(CreateMode.EPHEMERAL).forPath("/path3");

// 创建一个节点，指定创建模式（临时节点），附带初始化内容
client.create().withMode(CreateMode.EPHEMERAL).forPath("/path", "demo".getBytes());

// 创建一个节点，指定创建模式（临时节点），附带初始化内容，并且自动递归创建父节点
client.create()
      .creatingParentContainersIfNeeded()
      .withMode(CreateMode.EPHEMERAL)
      .forPath("/abc/path", "init".getBytes());

// creatingParentContainersIfNeeded 会自动的创建父节点
```

删除节点：

```java
// 删除一个节点, 此方法只能删除叶子节点，否则会抛出异常。
client.delete().forPath("/path");

// 删除一个节点，并且递归删除其所有的子节点
client.delete().deletingChildrenIfNeeded().forPath("/path");

// 删除一个节点，强制指定版本进行删除
client.delete().withVersion(100).forPath("/path");

// 删除一个节点，强制保证删除
client.delete().guaranteed().forPath("/path");

// 上面的多个流式接口是可以自由组合
```

读取数据节点数据

```java
// 读取一个节点的数据内容
byte[] data = client.getData().forPath("/path2");

// 读取一个节点的数据内容，同时获取到该节点的stat
Stat stat = new Stat();
byte[] data = client.getData()
        .storingStatIn(stat)
        .forPath("/path2");
```

更新数据节点数据

```java
// 更新一个节点的数据内容
client.setData().forPath("/path","data".getBytes());

// 更新一个节点的数据内容，强制指定版本进行更新
client.setData().withVersion(10086).forPath("/path","data".getBytes());

// 检查节点是否存在, 该方法返回一个Stat实例，不存在，则返回null。
Stat stat = client.checkExists().forPath("/path");

// 获取某个节点的所有子节点路径
List<String> list = client.getChildren().forPath("/path");
```

CuratorFramework的实例包含`inTransaction()`接口方法，调用此方法开启一个ZooKeeper事务. 可以复合`create`, `setData`, `check`, `and/or delete` 等操作然后调用`commit()`作为一个**原子操作提交**。一个例子如下：

```java
 client.inTransaction()
                .check().forPath("/path")
                .and()
                .create().withMode(CreateMode.EPHEMERAL).forPath("/path", "data".getBytes())
                .and()
                .setData().withVersion(1000).forPath("/path", "data2".getBytes())
                .and()
                .commit();
```

上面提到的创建、删除、更新、读取等方法都是同步的，`Curator`提供异步接口，引入了`BackgroundCallback`接口用于处理异步接口调用之后服务端返回的结果信息。`BackgroundCallback`接口中一个重要的回调值为`CuratorEvent`，里面包含事件类型、响应码和节点的详细信息。如下为`CuratorEvent`的类型

![image-20230825174343790](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230825174343790.png)

**响应码(`getResultCode()`)**

![image-20230825180505319](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230825180505319.png)

```java
ExecutorService executor = Executors.newFixedThreadPool(2);
client.create().creatingParentsIfNeeded()
                .withMode(CreateMode.EPHEMERAL)
                // 异步
                // .inBackground()
                .inBackground((client1, event) -> {
                    // 事件类型
                    CuratorEventType type = event.getType();
                    // 结果编码
                    int resultCode = event.getResultCode();
                    System.out.println("事件类型: " + type + ", 结果编码: " + resultCode);
                }, executor)
                .forPath("/path");

// 如果inBackground()方法不指定executor，那么会默认使用Curator的EventThread去进行异步处理。

   /**
     * 事务管理：碰到异常，事务会回滚
     * @throws Exception
     */
    @Test
    public void testTransaction() throws Exception{
        //定义几个基本操作
        CuratorOp createOp = client.transactionOp().create()
                .forPath("/curator/one_path","some data".getBytes());

        CuratorOp setDataOp = client.transactionOp().setData()
                .forPath("/curator","other data".getBytes());

        CuratorOp deleteOp = client.transactionOp().delete()
                .forPath("/curator");

        //事务执行结果
        List<CuratorTransactionResult> results = client.transaction()
                .forOperations(createOp,setDataOp,deleteOp);

        //遍历输出结果
        for(CuratorTransactionResult result : results){
            System.out.println("执行结果是： " + result.getForPath() + "--" + result.getType());
        }
    }
//因为节点“/curator”存在子节点，所以在删除的时候将会报错，事务回滚
```

监听：

**Path Catch**

zookeeper原生支持通过注册`Watcher`来进行事件监听，但是开发者需要反复注册(Watcher只能单次注册单次使用)。**Cache是Curator中对事件监听的包装，可以看作是对事件监听的本地缓存视图，能够自动为开发者处理反复注册监听**。`PathChildrenCache` 这个类为一个节点的所有子节点创建监听器。当节点状态发生变化后，能够完成指定的动作，这种功能在RPC中用于实现订阅某个功能。本项目中的实现如下，当发生变化后更新本类中自带的服务list：

```java
    private static void registerWatcher(CuratorFramework zkClient, String rpcServiceName) throws Exception {
        String servicePath = ZK_REGISTER_ROOT_PATH + "/" + rpcServiceName;
        // 创建一个pathChildrenCache
        PathChildrenCache pathChildrenCache = new PathChildrenCache(zkClient, servicePath, true);
        // 创建一个监听器，用于指定出现特定事件后需要执行的动作
        PathChildrenCacheListener pathChildrenCacheListener = (curatorFramework, pathChildrenCacheEvent) -> {
            List<String> serviceAddresses = curatorFramework.getChildren().forPath(servicePath);
            SERVICE_ADDRESS_MAP.put(rpcServiceName, serviceAddresses);
        };
        
        // 将监听器注册到pathChildrenCache中
        pathChildrenCache.getListenable().addListener(pathChildrenCacheListener);
        
       // 启动pathChildrenCache
        pathChildrenCache.start();
    }

```

`pathChildrenCache.start()`可以通过在start()中传入`StartMode`来设置启动状态：

`PathChildrenCache.StartMode.NORMAL`：正常初始化。

`PathChildrenCache.StartMode.BUILD_INITIAL_CACHE`：在调用start()之前会调用rebuild()。

`PathChildrenCache.StartMode.BUILD_INITIAL_CACHE`： 当Cache初始化数据后发送一个`PathChildrenCacheEvent.Type#INITIALIZED`事件

`addListener(PathChildrenCacheListener listener)`可以增加listener监听缓存的变化。 `getCurrentData()`方法返回一个List对象，可以遍历所有的子节点。

当一个方法查询某个节点的子节点后（获取了某个服务），注册`registerWatcher`监听提供该服务的服务器的变化

```java
public static List<String> getChildrenNodes(CuratorFramework zkClient, String rpcServiceName) {
        // 如果这个子节点的服务之前查询过,直接从cache中获取
        if (SERVICE_ADDRESS_MAP.containsKey(rpcServiceName)) {
            return SERVICE_ADDRESS_MAP.get(rpcServiceName);
        }
        List<String> result = null;
        String servicePath = ZK_REGISTER_ROOT_PATH + "/" + rpcServiceName;
        try {
            result = zkClient.getChildren().forPath(servicePath);
            SERVICE_ADDRESS_MAP.put(rpcServiceName, result);
            // 为这个节点的子节点注册watcher
            registerWatcher(zkClient, rpcServiceName);
        } catch (Exception e) {
            log.error("get children nodes for path [{}] fail", servicePath);
        }
        return result;
    }

// 一个通用的示例：
cache.getListenable()
        .addListener((client1, event) -> {
            // 事件类型
            PathChildrenCacheEvent.Type type = event.getType();
            System.out.println("事件类型：" + type);
            // 子节点数据
            ChildData data = event.getData();
            System.out.println("子节点数据：" + data);
        });
```

注意：如果`new PathChildrenCache(client, PATH, cacheData)`中的参数`cacheData`值设置为`false`，则示例中的`event.getData()`将返回null，cache将不会缓存节点数据。

**Node Cache**

`Node Cache`与`Path Cache`类似，**`Node Cache`只是监听某一个特定的节点**。它涉及到下面的三个类：

- `NodeCache`：Node Cache实现类
- `NodeCacheListener`：节点监听器
- `ChildData`： 节点数据

`getCurrentData()`将得到节点当前的状态，通过它的状态可以得到当前的值。

```java
// 创建NodeCache
NodeCache nodeCache = new NodeCache(client, PATH);
// 必须要先start
nodeCache.start();

NodeCacheListener listener = () -> {
    System.out.println("节点变化");
    ChildData currentData = nodeCache.getCurrentData();
    if (currentData != null) {
        System.out.println("节点数据：" + currentData);
    }else {
        System.out.println("节点无数据");
    }
};
nodeCache.getListenable().addListener(listener);
```

**Tree Cache**

Tree Cache可以监控整个树上的所有节点，主要涉及到下面四个类：

- `TreeCache`：Tree Cache实现类
- `TreeCacheListener`：监听器类
- `TreeCacheEvent`：触发的事件类
- `ChildData`：节点数据

```java
TreeCache treeCache = new TreeCache(client, PATH);
treeCache.start();

treeCache.getListenable().addListener((client1, event) -> {
    TreeCacheEvent.Type type = event.getType();
    ChildData data = event.getData();
    System.out.println("事件类型：" + type + ", 节点数据：" + data);
});
```

eg2:

```java
 /**
         * 在注册监听器的时候，如果传入此参数，当事件触发时，逻辑由线程池处理
         */
        ExecutorService pool = Executors.newFixedThreadPool(2);

        /**
         * 监听数据节点的变化情况
         */
        final NodeCache nodeCache = new NodeCache(client, "/zk-huey/cnode", false);
        nodeCache.start(true);
        nodeCache.getListenable().addListener(
            new NodeCacheListener() {
                @Override
                public void nodeChanged() throws Exception {
                    System.out.println("Node data is changed, new data: " + 
                        new String(nodeCache.getCurrentData().getData()));
                }
            }, 
            pool
        );

        /**
         * 监听子节点的变化情况
         */
        final PathChildrenCache childrenCache = new PathChildrenCache(client, "/zk-huey", true);
        childrenCache.start(StartMode.POST_INITIALIZED_EVENT);
        childrenCache.getListenable().addListener(
            new PathChildrenCacheListener() {
                @Override
                public void childEvent(CuratorFramework client, PathChildrenCacheEvent event)
                        throws Exception {
                        switch (event.getType()) {
                        case CHILD_ADDED:
                            System.out.println("CHILD_ADDED: " + event.getData().getPath());
                            break;
                        case CHILD_REMOVED:
                            System.out.println("CHILD_REMOVED: " + event.getData().getPath());
                            break;
                        case CHILD_UPDATED:
                            System.out.println("CHILD_UPDATED: " + event.getData().getPath());
                            break;
                        default:
                            break;
                    }
                }
            },
            pool
        );

        client.setData().forPath("/zk-huey/cnode", "world".getBytes());

        Thread.sleep(10 * 1000);
        pool.shutdown();
        client.close();
```

Leader选举

指派一个进程作为组织者，将任务分发给各节点。 在任务开始前， 哪个节点都不知道谁是leader(领导者)或者coordinator(协调者). 当选举算法开始执行后， 每个节点最终会得到一个唯一的节点作为任务leader. 除此之外，选举还经常会发生在leader意外宕机的情况下，新的leader要被选举出来。

**在zookeeper集群中，leader负责写操作，然后通过Zab协议实现follower的同步，leader或者follower都可以处理读操作**。 Curator有两种leader选举的recipe,分别是`LeaderSelector`和`LeaderLatch`。

- `LeaderSelector`：所有存活的客户端不间断的轮流做Leader。
- `LeaderLatch`：一旦选举出Leader，除非有客户端挂掉重新触发选举，否则不会交出领导权。

LeaderLatch

`LeaderLatch`会和其它使用相同`latch path`的其它`LeaderLatch`交涉，然后其中一个最终会被选举为`leader`

类似JDK的`CountDownLatch`， `LeaderLatch`在请求成为`leadership`会`block`(阻塞)，一旦不使用`LeaderLatch`了，必须调用`close()`方法。 如果它是leader,会释放leadership， 其它的参与者将会选举一个leader。

异常处理： 可以增加`ConnectionStateListener`来监听网络连接问题。 当`SUSPENDED`或`LOST`时, leader不再认为自己还是leader。当`LOST`后连接重连后`RECONNECTED`, LeaderLatch会删除先前的ZNode然后重新创建一个。**LeaderLatch用户必须考虑导致leadership丢失的连接问题。 强烈推荐你使用`ConnectionStateListener`**。 leaderlatch中并没有ConnectionStateListener，这个类要添加在client中

```java
/**
 * 参与选举的所有节点，会创建一个顺序节点，其中最小的 节点会设置为 master 节点, 没抢到 Leader 的节点都监听 前一个节点的删除事件，
 * 在前一个节点删除后进行重新抢主，当 master 节点手动调用 close()方法或者 master 节点挂了之后，后续的子节点会抢占 master。
 其中 spark 使用的就是这种方法
 * 
 * 
 */
public class LeaderLatchTest {

    protected static String PATH = "/francis/leader";
    private final static String connectionInfo = "127.0.0.1:2181";
    private static final int CLIENT_QTY = 10;

    public static void main(String[] args) {
        List<CuratorFramework> clients = Lists.newArrayList();
        List<LeaderLatch> examples = Lists.newArrayList();

        try {
            /**
             * 创建10个客户端，并且创建对应的LeaderLatch
             */
            for (int i = 0; i < CLIENT_QTY; i++) {
                CuratorFramework client
                        = CuratorFrameworkFactory.newClient(connectionInfo, new ExponentialBackoffRetry(20000, 3));
                clients.add(client);
                // 创建LeaderLatch latch
                LeaderLatch latch = new LeaderLatch(client, PATH, "Client #" + i);

                latch.addListener(new LeaderLatchListener(){
                    @Override
                    public void isLeader() {
                        System.out.println("I am Leader");
                    }

                    @Override
                    public void notLeader() {
                        System.out.println("I am not Leader");
                    }
                });

                examples.add(latch);
                client.start();
                // 启动每个latch
                latch.start();
            }

            Thread.sleep(10_000);
            /**
             * 获取当前的leader
             */
            LeaderLatch currentLeader = null;
            for (LeaderLatch latch : examples) {
                if (latch.hasLeadership()) {
                    currentLeader = latch;
                }
            }
            System.out.println("current leader is " + currentLeader.getId());
            System.out.println("release the leader " + currentLeader.getId());
            // 只能通过close释放当前的领导权
            currentLeader.close();

            Thread.sleep(5000);

            /**
             * 再次获取leader
             */
            for (LeaderLatch latch : examples) {
                // 找到被选为
                if (latch.hasLeadership()) {
                    currentLeader = latch;
                }
            }
            System.out.println("current leader is " + currentLeader.getId());
            System.out.println("release the leader " + currentLeader.getId());
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            for (LeaderLatch latch : examples) {
                if (LeaderLatch.State.CLOSED != latch.getState())
                    CloseableUtils.closeQuietly(latch);
            }
            for (CuratorFramework client : clients) {
                CloseableUtils.closeQuietly(client);
            }
        }
    }
}
```

`LeaderSelector`使用的时候主要涉及下面几个类

- `LeaderSelector`
- `LeaderSelectorListener`
- `LeaderSelectorListenerAdapter`
- `CancelLeadershipException`

类似`LeaderLatch`,`LeaderSelector`必须start:`leaderSelector.start()`; 一旦启动，当实例取得领导权时你的listener的`takeLeadership()`方法被调用。而`takeLeadership()`方法只有领导权被释放时才返回。 当你不再使用LeaderSelector实例时，应该调用它的`close()`方法。

**异常处理**：`LeaderSelectorListener`类继承`ConnectionStateListener`。`LeaderSelector`必须小心连接状态的改变。如果实例成为leader, 它应该响应`SUSPENDED`或`LOST`。 当`SUSPENDED`状态出现时，实例必须假定在重新连接成功之前, 它可能不再是leader了。 如果LOST状态出现， 实例不再是leader， `takeLeadership()`方法返回。

**重要**: 推荐处理方式是当收到`SUSPENDED` 或`LOST`时抛出`CancelLeadershipException`异常。这是会导致`LeaderSelector`实例中断并取消执行`takeLeadership`方法的异常。这非常重要， 你必须考虑扩展`LeaderSelectorListenerAdapter`。 `LeaderSelectorListenerAdapter`提供了推荐的处理逻辑。

Eg.1:

```java
/**
 * 当实例被选为leader之后，调用takeLeadership方法进行业务逻辑处理，处理完成即释放领导权。
 * autoRequeue()方法的调用确保此实例在释放领导权后还可能获得领导权。
 * 这样保证了每个节点都可以获得领导权。
 *
 * @author 陈添明
 * @date 2019/11/10
 */
public class LeaderSelectorTest {

    public static void main(String[] args) throws InterruptedException {
        List<LeaderSelector> leaderSelectors = new ArrayList<>();
        List<CuratorFramework> clients = new ArrayList<>();
        for (int i = 0; i < 10; i++) {
            CuratorFramework client = CuratorFrameworkFactory.newClient("localhost:2181", new ExponentialBackoffRetry(1000, 3));
            client.start();
            clients.add(client);

            LeaderSelector leaderSelector = new LeaderSelector(client, "/master", new LeaderSelectorListenerAdapter() {
                @Override
                public void takeLeadership(CuratorFramework curatorFramework) throws Exception {
                    System.out.println(Thread.currentThread().getName() + " is a leader");
                    Thread.sleep(Integer.MAX_VALUE);
                }

                @Override
                public void stateChanged(CuratorFramework client, ConnectionState newState) {
                    super.stateChanged(client, newState);
                }
            });
            leaderSelectors.add(leaderSelector);
        }
        leaderSelectors.forEach(leaderSelector -> {
            leaderSelector.autoRequeue();
            leaderSelector.start();
            try {
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });

        System.out.println("==================");
        clients.forEach(client -> {
            client.close();
            try {
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });
        Thread.sleep(100 * 1000);
    }
}

```

Eg.2:

```java
package referTooltest;

import org.apache.curator.framework.CuratorFramework;
import org.apache.curator.framework.CuratorFrameworkFactory;
import org.apache.curator.framework.recipes.leader.LeaderSelector;
import org.apache.curator.framework.recipes.leader.LeaderSelectorListener;
import org.apache.curator.framework.state.ConnectionState;
import org.apache.curator.retry.RetryNTimes;
import org.apache.curator.utils.EnsurePath;

/**
 * Curator framework's leader election test.
 * Output:
 *  LeaderSelector-2 take leadership!
 *  LeaderSelector-2 relinquish leadership!
 *  LeaderSelector-1 take leadership!
 *  LeaderSelector-1 relinquish leadership!
 *  LeaderSelector-0 take leadership!
 *  LeaderSelector-0 relinquish leadership!
 *      ...
 */
public class LeaderSelectorTest {

    /** Zookeeper info */
    private static final String ZK_ADDRESS = "192.168.137.128:2181";
    private static final String ZK_PATH = "/zktest";

    public static void main(String[] args) throws InterruptedException {
        LeaderSelectorListener listener = new LeaderSelectorListener() {
            @Override
            public void takeLeadership(CuratorFramework client) throws Exception {
                System.out.println(Thread.currentThread().getName() + " take leadership!");

                // takeLeadership() method should only return when leadership is being relinquished.
                Thread.sleep(5000L);

                System.out.println(Thread.currentThread().getName() + " relinquish leadership!");
            }

            @Override
            public void stateChanged(CuratorFramework client, ConnectionState state) {
            }
        };

        new Thread(() -> {
            registerListener(listener);
        }).start();

        new Thread(() -> {
            registerListener(listener);
        }).start();

        new Thread(() -> {
            registerListener(listener);
        }).start();

        Thread.sleep(Integer.MAX_VALUE);
    }

    private static void registerListener(LeaderSelectorListener listener) {
        // 1.Connect to zk
        CuratorFramework client = CuratorFrameworkFactory.newClient(
                ZK_ADDRESS,
                new RetryNTimes(10, 5000)
        );
        client.start();

        // 2.Ensure path
        try {
            new EnsurePath(ZK_PATH).ensure(client.getZookeeperClient());
        } catch (Exception e) {
            e.printStackTrace();
        }

        // 3.Register listener
        LeaderSelector selector = new LeaderSelector(client, ZK_PATH, listener);
        selector.autoRequeue();
        selector.start();
    }
}
```

**分布式锁**

1. 推荐使用`ConnectionStateListener`监控连接的状态，因为当连接LOST时你不再拥有锁。
2. 分布式的锁全局同步，这意味着任何一个时间点不会有两个客户端都拥有相同的锁。

**可重入共享锁—Shared Reentrant Lock**

`Shared`意味着锁是全局可见的，客户端都可以请求锁。`Reentrant`和JDK的`ReentrantLock`类似，即可重入。意味着**同一个客户端在拥有锁的同时，可以多次获取，不会被阻塞**。 它是由类`InterProcessMutex`来实现。 它的构造函数为：`public InterProcessMutex(CuratorFramework client, String path)`。

- 通过`acquire()`获得锁，并提供超时机制。
- 通过`release()`方法释放锁。`InterProcessMutex`实例可以重用。

zookeeper还提供了可协商的撤销机制，通过为`mutex`设置*撤销监听器*来支持撤销`mutex`, 通过调用`makeRevocable(RevocationListener<T> listener)`来实现。

如果你请求撤销当前的锁，可以调用`Revoker.attemptRevoke(CuratorFramework client, String path)`方法,此时`RevocationListener`将会回调。

首先让我们创建一个模拟的共享资源， 这个资源期望只能单客户端的访问，否则会有并发问题。

```java
/**
 * 共享资源
 */
public class FakeLimitedResource {
    private final AtomicBoolean inUse = new AtomicBoolean(false);
    private final Random random = new Random(System.currentTimeMillis());

    /**
     * use方法最多只能有一个客户端调用
     * 否则，抛出异常
     * @throws InterruptedException
     */
    public void use() throws InterruptedException {
        // 真实环境中我们会在这里访问/维护一个共享的资源
        //这个例子在使用锁的情况下不会非法并发异常IllegalStateException
        //但是在无锁的情况由于sleep了一段时间，很容易抛出异常
        if (!inUse.compareAndSet(false, true)) {
            throw new IllegalStateException("同一时间，只能被一个客户端访问！！！");
        }
        try {
            Thread.sleep(random.nextInt(2_000));
        } finally {
            inUse.set(false);
        }
    }
}
```

然后创建一个`InterProcessMutexDemo`类， 它负责请求锁， 使用资源，释放锁这样一个完整的访问过程。

```java
/**
 *
 * 然后创建一个InterProcessMutexDemo类， 它负责请求锁， 使用资源，释放锁这样一个完整的访问过程。
 * @author 陈添明
 * @date 2018/12/15
 */

public class InterProcessMutexDemo {


    /**
     * 代码也很简单，生成10个client， 每个client重复执行10次 请求锁–访问资源–释放锁的过程。
     * 每个client都在独立的线程中。 结果可以看到，锁是随机的被每个实例排他性的使用。
     */

    private InterProcessMutex lock;
    private final FakeLimitedResource resource;
    private final String clientName;

    public InterProcessMutexDemo(CuratorFramework client, String lockPath, FakeLimitedResource resource, String clientName) {
        this.resource = resource;
        this.clientName = clientName;
        this.lock = new InterProcessMutex(client, lockPath);
        // 将锁设为可撤销的. 当别的进程或线程想让你释放锁时Listener会被调用。
        lock.makeRevocable((forLock -> {

        }));
    }


    /**
     * 同一线程再次 acquire，首先判断当前的 映射表内(threadData)是否有该线程的锁信息，如果有 则原子+1，然后返回
     * 可重入互斥锁
     * 加锁执行
     * @param time
     * @param unit
     * @throws Exception
     */
    public void doWork(long time, TimeUnit unit) throws Exception {
        if (!lock.acquire(time, unit)) {
            throw new IllegalStateException(clientName + "获取互斥锁锁失败");
        }
        try {
            System.out.println(clientName + " 获取到互斥锁");
            resource.use(); //access resource exclusively
        } finally {
            System.out.println(clientName + " 释放互斥锁");
            lock.release(); // always release the lock in a finally block
        }
    }

    private static final int QTY = 5;
    private static final int REPETITIONS = QTY * 10;
    private static final String PATH = "/examples/locks";

    public static void main(String[] args) throws Exception {
        final FakeLimitedResource resource = new FakeLimitedResource();
        ExecutorService service = Executors.newFixedThreadPool(QTY);
        final TestingServer server = new TestingServer();
        try {
            for (int i = 0; i < QTY; ++i) {
                final int index = i;
                Callable<Void> task = () -> {
                    // 创建客户端
                    CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3));
                    try {
                        // 启动
                        client.start();
                        final InterProcessMutexDemo example = new InterProcessMutexDemo(client, PATH, resource, "Client " + index);
                        // 执行
                        for (int j = 0; j < REPETITIONS; ++j) {
                            example.doWork(10, TimeUnit.SECONDS);
                        }
                    } catch (Throwable e) {
                        e.printStackTrace();
                    } finally {
                        CloseableUtils.closeQuietly(client);
                    }
                    return null;
                };
                service.submit(task);
            }
            service.shutdown();
            service.awaitTermination(10, TimeUnit.MINUTES);
        } finally {
            CloseableUtils.closeQuietly(server);
        }
    }

}
```

**不可重入共享锁—Shared Lock**

这个锁和上面的`InterProcessMutex`相比，就是少了`Reentrant`的功能，也就意味着它不能在同一客户端中重入。这个类是`InterProcessSemaphoreMutex`,使用方法和`InterProcessMutex`类似

> 源码见`InterProcessSemaphoreMutexDemo`类。

运行后发现，有且只有一个client成功获取第一个锁(第一个`acquire()`方法返回true)，然后它自己阻塞在第二个`acquire()`方法，获取第二个锁超时；其他所有的客户端都阻塞在第一个`acquire()`方法超时并且抛出异常。 这样也就验证了`InterProcessSemaphoreMutex`实现的锁是不可重入的。

**可重入读写锁—Shared Reentrant Read Write Lock**

类似JDK的`ReentrantReadWriteLock`，读写锁一个负责读操作，另外一个负责写操作。读操作在写锁没被使用时可同时由多个进程使用，而写锁在使用时不允许读(阻塞)。 此锁是可重入的。一个拥有写锁的线程可重入读锁，但是读锁却不能进入写锁。这也意味着写锁可以降级成读锁， 比如`请求写锁 --->请求读锁--->释放读锁 ---->释放写锁`。从读锁升级成写锁是不行的。 可重入读写锁主要由两个类实现：`InterProcessReadWriteLock`、`InterProcessMutex`。使用时首先创建一个`InterProcessReadWriteLock`实例，然后再根据你的需求得到读锁或者写锁，读写锁的类型是`InterProcessMutex`。

**信号量—Shared Semaphore**

一个计数的信号量类似JDK的`Semaphore`。 JDK中`Semaphore`维护的一组许可(permits)，而`Curator`中称之为租约(Lease)。 有两种方式可以决定`semaphore`的最大租约数。第一种方式是用户给定`path`并且指定最大`LeaseSize`。第二种方式用户给定path并且使用`SharedCountReader`类。如果不使用`SharedCountReader`, 必须保证所有实例在多进程中使用相同的(最大)租约数量,否则有可能出现A进程中的实例持有最大租约数量为10，但是在B进程中持有的最大租约数量为20，此时租约的意义就失效了。

**调用`acquire()`会返回一个租约对象。 客户端必须在`finally`中`close`这些租约对象，否则这些租约会丢失掉**。 但是，如果客户端`session`由于某种原因比如`crash`丢掉， 那么这些客户端持有的租约会自动`close`， 这样其它客户端可以继续使用这些租约。 租约还可以通过下面的方式返还：

```java
public void returnAll(Collection<Lease> leases)
public void returnLease(Lease lease)
```

**注意你可以一次性请求多个租约，如果`Semaphore`当前的租约不够，则请求线程会被阻塞**。 同时还提供了超时的重载方法。

```java
public Lease acquire()
public Collection<Lease> acquire(int qty)
public Lease acquire(long time, TimeUnit unit)
public Collection<Lease> acquire(int qty, long time, TimeUnit unit)
```

`Shared Semaphore`使用的主要类包括下面几个： `InterProcessSemaphoreV2`、`Lease`、`SharedCountReader`。 使用示例代码如下：

```java
public class InterProcessSemaphoreDemo {


    private static final int MAX_LEASE = 10;
    private static final String PATH = "/examples/locks";

    /**
     * 首先我们先获得了5个租约， 最后我们把它还给了semaphore。 接着请求了一个租约，
     * 因为semaphore还有5个租约，所以请求可以满足，返回一个租约，还剩4个租约。
     * 然后再请求5个租约，因为租约不够，阻塞到超时，还是没能满足，返回结果为null(租约不足会阻塞到超时，然后返回null，不会主动抛出异常；如果不设置超时时间，会一致阻塞)。
     *
     上面说讲的锁都是公平锁(fair)。 总ZooKeeper的角度看， 每个客户端都按照请求的顺序获得锁，不存在非公平的抢占的情况。
     * @param args
     * @throws Exception
     */

    public static void main(String[] args) throws Exception {
        FakeLimitedResource resource = new FakeLimitedResource();
        try (TestingServer server = new TestingServer()) {

            // 创建客户端并启动
            CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3));
            client.start();

            // 信号量
            InterProcessSemaphoreV2 semaphore = new InterProcessSemaphoreV2(client, PATH, MAX_LEASE);

            // 获取5个租约
            Collection<Lease> leases = semaphore.acquire(5);
            System.out.println("get " + leases.size() + " leases");

            // 获取1个租约
            Lease lease = semaphore.acquire();
            System.out.println("get another lease");

            // 处理资源
            resource.use();

            // 在获取5个租约，由于最多只有10个，前面已经使用了6个，租约不足。
            // 如果在获得所有租赁之前时间到期，则获得的租赁子集将自动关闭
            Collection<Lease> leases2 = semaphore.acquire(5, 10, TimeUnit.SECONDS);
            System.out.println("Should timeout and acquire return " + leases2);

            // 返还一个租约
            System.out.println("return one lease");
            semaphore.returnLease(lease);

            // 返还多个租约
            System.out.println("return another 5 leases");
            semaphore.returnAll(leases);
        }
    }
}
```

**共享 shared**

共享计数—SharedCount

这个类使用`int`类型来计数。 主要涉及三个类。`SharedCount`、`SharedCountReader`、`SharedCountListener`。 `SharedCount`代表计数器， 可以为它增加一个`SharedCountListener`，当计数器改变时此`Listener`可以监听到改变的事件，而`SharedCountReader`可以读取到最新的值， 包括字面值和带版本信息的值`VersionedValue`。

**分布式原子类-atomic**

**DistributedAtomicLong**

顾名思义，计数器是用来计数的, 利用ZooKeeper可以实现一个集群共享的计数器。 只要使用相同的`path`就可以得到最新的计数器值， 这是由ZooKeeper的一致性保证的。 除了计数的范围比`SharedCount`大了之外， 它首先尝试使用乐观锁的方式设置计数器， 如果不成功(比如期间计数器已经被其它client更新了)， 它使用`InterProcessMutex`方式来更新计数值。

此计数器有一系列的操作：

- `get()`: 获取当前值
- `increment()`： 加一
- `decrement()`: 减一
- `add()`： 增加特定的值
- `subtract()`: 减去特定的值
- `trySet()`: 尝试设置计数值
- `forceSet()`: 强制设置计数值

**分布式屏障—Barrier**

分布式`Barrier`是这样一个类： 它会阻塞所有节点上的等待进程，直到某一个被满足， 然后所有的节点继续进行。 比如赛马比赛中， 等赛马陆续来到起跑线前。 一声令下，所有的赛马都飞奔而出。

**DistributedBarrier**

`DistributedBarrier`类实现了栅栏的功能。 它的构造函数为`public DistributedBarrier(CuratorFramework client, String barrierPath)`。

1. 首先你需要设置栅栏，它将阻塞在它上面等待的线程:`setBarrier()`。
2. 然后需要阻塞的线程调用方法等待放行条件:` waitOnBarrier()`。
3. 当条件满足时，移除栅栏，所有等待的线程将继续执行：`removeBarrier()`。

异常处理`DistributedBarrier`会监控连接状态，当连接断掉时`waitOnBarrier()`方法会抛出异常。

```java
public class DistributedBarrierDemo {

    private static final int QTY = 5;
    private static final String PATH = "/examples/barrier";


    /**
     * 这个例子创建了controlBarrier来设置栅栏和移除栅栏。 我们创建了5个线程，在此Barrier上等待。
     * 最后移除栅栏后所有的线程才继续执行。
     * @param args
     * @throws Exception
     */

    public static void main(String[] args) throws Exception {
        try (TestingServer server = new TestingServer()) {
            CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3));
            client.start();
            ExecutorService service = Executors.newFixedThreadPool(QTY);

            // 创建barrier
            DistributedBarrier controlBarrier = new DistributedBarrier(client, PATH);
            // 设置barrier
            controlBarrier.setBarrier();

            for (int i = 0; i < QTY; ++i) {
                final DistributedBarrier barrier = new DistributedBarrier(client, PATH);
                final int index = i;
                Callable<Void> task = () -> {
                    Thread.sleep((long) (3 * Math.random()));
                    System.out.println("Client #" + index + " waits on Barrier");
                    barrier.waitOnBarrier();
                    System.out.println("Client #" + index + " begins");
                    return null;
                };
                service.submit(task);
            }
            Thread.sleep(10000);
            System.out.println("all Barrier instances should wait the condition");
            // 放行
            controlBarrier.removeBarrier();
            service.shutdown();
            service.awaitTermination(10, TimeUnit.MINUTES);

            Thread.sleep(20000);
        }
    }
}
```



**双栅栏—DistributedDoubleBarrier**

双栅栏允许客户端在计算的开始和结束时同步。当足够的进程加入到双栅栏时，进程开始计算， 当计算完成时，离开栅栏。 双栅栏类是`DistributedDoubleBarrier`。 构造函数为:

```java
public DistributedDoubleBarrier(CuratorFramework client,
                                String barrierPath,
                                int memberQty)
```

`memberQty`是成员数量，当`enter()`方法被调用时，成员被阻塞，直到所有的成员都调用了`enter()`。 当`leave()`方法被调用时，它也阻塞调用线程，直到所有的成员都调用了`leave()`。 就像百米赛跑比赛， 发令枪响， 所有的运动员开始跑，等所有的运动员跑过终点线，比赛才结束。

```java
public class DistributedDoubleBarrierDemo {

    private static final int QTY = 5;
    private static final String PATH = "/examples/barrier";

    public static void main(String[] args) throws Exception {
        try (TestingServer server = new TestingServer()) {
            CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3));
            client.start();
            ExecutorService service = Executors.newFixedThreadPool(QTY);
            for (int i = 0; i < QTY; ++i) {

                // 创建双栅栏
                final DistributedDoubleBarrier barrier = new DistributedDoubleBarrier(client, PATH, QTY);
                final int index = i;
                Callable<Void> task = () -> {

                    Thread.sleep((long) (3 * Math.random()));
                    System.out.println("Client #" + index + " enters");
                    barrier.enter();
                    System.out.println("Client #" + index + " begins");
                    Thread.sleep((long) (3000 * Math.random()));
                    barrier.leave();
                    System.out.println("Client #" + index + " left");
                    return null;
                };
                service.submit(task);
            }

            service.shutdown();
            service.awaitTermination(10, TimeUnit.MINUTES);
            Thread.sleep(Integer.MAX_VALUE);
        }
    }

}
```

链接：https://juejin.cn/post/6984742386744164388

分布式编程时，比如最容易碰到的情况就是应用程序在线上多机部署，于是当多个应用同时访问某一资源时，就需要某种机制去协调它们。例如，现在一台应用正在rebuild缓存内容，要临时锁住某个区域暂时不让访问；又比如调度程序每次只想一个任务被一台应用执行等等。

下面的程序会启动两个线程t1和t2去争夺锁，拿到锁的线程会占用5秒。运行多次可以观察到，有时是t1先拿到锁而t2等待，有时又会反过来。Curator会用我们提供的lock路径的结点作为全局锁，这个结点的数据类似这种格式：[_c_64e0811f-9475-44ca-aa36-c1db65ae5350-lock-0000000005]，每次获得锁时会生成这种串，释放锁时清空数据。

```java
import org.apache.curator.framework.CuratorFramework;
import org.apache.curator.framework.CuratorFrameworkFactory;
import org.apache.curator.framework.recipes.locks.InterProcessMutex;
import org.apache.curator.retry.RetryNTimes;

import java.util.concurrent.TimeUnit;

/**
 * Curator framework's distributed lock test.
 */
public class CuratorDistrLockTest {

    /** Zookeeper info */
    private static final String ZK_ADDRESS = "192.168.1.100:2181";
    private static final String ZK_LOCK_PATH = "/zktest";

    public static void main(String[] args) throws InterruptedException {
        // 1.Connect to zk
        CuratorFramework client = CuratorFrameworkFactory.newClient(
                ZK_ADDRESS,
                new RetryNTimes(10, 5000)
        );
        client.start();
        System.out.println("zk client start successfully!");

        Thread t1 = new Thread(() -> {
            doWithLock(client);
        }, "t1");
        Thread t2 = new Thread(() -> {
            doWithLock(client);
        }, "t2");

        t1.start();
        t2.start();
    }

    private static void doWithLock(CuratorFramework client) {
        InterProcessMutex lock = new InterProcessMutex(client, ZK_LOCK_PATH);
        try {
            if (lock.acquire(10 * 1000, TimeUnit.SECONDS)) {
                System.out.println(Thread.currentThread().getName() + " hold lock");
                Thread.sleep(5000L);
                System.out.println(Thread.currentThread().getName() + " release lock");
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            try {
                lock.release();
            } catch (Exception e) {
                e.printStackTrace();
            }
        }
    }
}
```

参考：

https://zifangsky.cn/1367.html

https://blog.csdn.net/stillcoolman/article/details/103733468

https://blog.csdn.net/qq_37960603/article/details/121835169

https://blog.csdn.net/ljimking/article/details/76835270

https://blog.csdn.net/jiyiqinlovexx/article/details/42649487

https://blog.csdn.net/ThreeAspects/article/details/108306687#:~:text=%2F%2F%E4%BC%9A%E8%AF%9D%E7%BB%88%E6%AD%A2%20case%20Expired%3A%7B%20isConnected%20%3D%20false%3B,checkNewConnectionString%20%3D%20false%3B%20handleExpiredSession%28%29%3B%20break%3B%20%7D

https://blog.csdn.net/qq_40882561/article/details/123681096

Curator重试机制：https://blog.csdn.net/qq_37960603/article/details/121548596

watcher:  https://blog.csdn.net/crazymakercircle/article/details/85922561

https://my.oschina.net/u/1241970/blog/918183

https://heapdump.cn/article/5271949?from=pc

https://developer.aliyun.com/article/227260#:~:text=Curator%E7%9A%84%E8%BF%9E%E6%8E%A5%E4%BA%8B%E4%BB%B6%E9%87%8C%E9%9D%A2%E5%87%A0%E4%B8%AA%E5%85%B3%E9%94%AE%E7%8A%B6%E6%80%81%201%20CONNECTED%20%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%BF%9E%E6%8E%A5%202%20SUSPENDED%20%E5%AF%B9%E5%BA%94%E5%8E%9F%E7%94%9F%E7%9A%84Disconnected,3%20LOST%20%E5%AF%B9%E5%BA%94%E5%8E%9F%E7%94%9F%E7%9A%84Expired%204%20RECONNECTED%20%E5%8C%85%E6%8B%ACsessionid%E4%B8%8D%E5%8F%98%E7%9A%84%E9%87%8D%E8%BF%9E%E5%92%8Csessionid%E5%8F%98%E5%8C%96%E7%9A%84%E9%87%8D%E8%BF%9E%EF%BC%8C%E5%A6%82%E6%9E%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BB%BA%E7%AB%8B%E4%BA%86EPHEMERAL%E8%8A%82%E7%82%B9%2C%E5%BF%85%E9%A1%BB%E5%9C%A8%E6%AD%A4%E4%BA%8B%E4%BB%B6%E4%B8%AD%E5%88%A4%E6%96%ADsessionId%E3%80%82%20%E5%AF%B9%E5%BA%94sessionId%E4%B8%8D%E5%8F%98%E7%9A%84%E6%83%85%E5%86%B5%EF%BC%8C%E8%BF%9E%E6%8E%A5%E6%96%AD%E5%BC%80%E6%9C%9F%E9%97%B4watch%E7%9A%84%E4%BA%8B%E4%BB%B6%E4%B8%8D%E4%BC%9A%E4%B8%A2%E5%A4%B1%EF%BC%8C%E5%A6%82%E6%9E%9CsessionId%E5%8F%98%E5%8C%96%EF%BC%8C%E5%88%99%E6%9C%9F%E9%97%B4watch%E7%9A%84%E4%BA%8B%E4%BB%B6%E4%BC%9A%E4%B8%A2%E5%A4%B1%E3%80%82



client从注册中心获取ip地址

RpcServiceConfig内部存储的是服务的信息，用于注册时告诉注册中心，我这个服务是什么版本的，从属于那个group，当服务器从客户端收到请求时会对这里面的信息进行核对，看看你请求的服务是不是我提供的服务

```java
public class RpcServiceConfig {
    /**
     * service version
     */
    private String version = "";
    /**
     * when the interface has multiple implementation classes, distinguish by group
     */
    private String group = "";

    /**
     * target service
     */
    private Object service;

    public String getRpcServiceName() {
        return this.getServiceName() + this.getGroup() + this.getVersion();
    }

    public String getServiceName() {
        return this.service.getClass().getInterfaces()[0].getCanonicalName();
    }
}

```

**负载均衡**

**一致性 hash 算法由麻省理工学院的 Karger 及其合作者于 1997 年提出的，算法提出之初是用于大规模缓存系统的负载均衡。**它的工作过程是这样的，首先根据 ip 或者其他的信息为缓存节点生成一个 hash，**并将这个 hash 投射到 [0, 2^32 - 1] 的圆环上**。当有查询或写入请求时，则为缓存项的 key 生成一个 hash 值。然后查找第一个大于或等于该 hash 值的缓存节点，并到这个节点中查询或写入缓存项。如果当前节点挂了，则在下一次查询或写入缓存时，为缓存项查找另一个大于其 hash 值的缓存节点即可。大致效果如下图所示，每个缓存节点在圆环上占据一个位置。如果缓存项的 key 的 hash 值小于缓存节点 hash 值，则到该缓存节点中存储或读取缓存项。比如下面绿色点对应的缓存项将会被存储到 cache-2 节点中。由于 cache-3 挂了，原本应该存到该节点中的缓存项最终会存储到 cache-4 节点中。

![image-20230826232001069](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230826232001069.png)

在一致性哈希算法中，不管是增加节点，还是宕机节点，受影响的区间仅仅是增加或者宕机服务器在哈希环空间中，**逆时针**方向遇到的第一台服务器之间的区间，其它区间不会受到影响。

但是一致性哈希也是存在问题的：

![image-20230826232047422](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230826232047422.png)

**当节点很少的时候可能会出现这样的分布情况，A 服务会承担大部分请求。这种情况就叫做数据倾斜。**

那如何解决数据倾斜的问题呢？

**加入虚拟节点。**

首先一个服务器根据需要可以有多个虚拟节点。假设一台服务器有 n 个虚拟节点。那么哈希计算时，可以使用 **IP + 端口 + 编号**的形式进行哈希值计算。其中的编号就是 0 到 n 的数字。由于 IP + 端口是一样的，所以这 n 个节点都是指向的同一台机器。

![image-20230826232213979](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230826232213979.png)

在没有加入虚拟节点之前，A 服务器承担了绝大多数的请求。但是假设每个服务器有一个虚拟节点（A-1，B-1，C-1），经过哈希计算后落在了如上图所示的位置。那么 A 服务器的承担的请求就在一定程度上（图中标注了五角星的部分）分摊给了 B-1、C-1 虚拟节点，实际上就是分摊给了 B、C 服务器。

**一致性哈希算法中，加入虚拟节点，可以解决数据倾斜问题。**

```java
package org.rpcframwork.core.loadbalance.loadbalancer;

import org.rpcframwork.core.codec.RpcRequestBody;
import org.rpcframwork.core.loadbalance.AbstractLoadBalance;
import org.rpcframwork.core.rpc_protocol.RpcRequest;

import java.nio.channels.Selector;
import java.nio.charset.StandardCharsets;
import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.util.List;
import java.util.Map;
import java.util.TreeMap;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;

public class ConsistentHashLoadBalance extends AbstractLoadBalance {
    private final ConcurrentMap<String, ConsistentHashSelector> selectors = new ConcurrentHashMap<String, ConsistentHashSelector>();
    @Override
    public String selectServiceAddress(List<String> serviceAddresses, RpcRequestBody rpcRequestBody) {
        return super.selectServiceAddress(serviceAddresses, rpcRequestBody);
    }

    @Override
    protected String doSelect(List<String> serviceAddresses, RpcRequestBody rpcRequestBody) {
        String key = rpcRequestBody.getRpcServiceName();

        int identityHashCode = System.identityHashCode(serviceAddresses);
        ConsistentHashSelector selector = selectors.get(key);
        if(selector == null || selector.identityHashCode != identityHashCode){
            selectors.put(key, new ConsistentHashSelector(serviceAddresses, identityHashCode));
            selector = selectors.get(key);
        }
        return selector.select(rpcRequestBody);
    }

    private static final class ConsistentHashSelector{
        private final TreeMap<Long, String> virtualServerNode;
        private final int replicaNumber = 160;
        private final int identityHashCode;

        public ConsistentHashSelector(List<String> serviceAddresses, int identityHashCode){
            this.identityHashCode = identityHashCode;
            this.virtualServerNode = new TreeMap<>();
            for(String address : serviceAddresses){
                for(int i = 0; i < replicaNumber / 4; i++){
                    // 对 address + i 进行 md5 运算，得到一个长度为16的字节数组
                    byte[] digest = md5(address + i);
                    for (int h = 0; h < 4; h++) {
                        // h = 0 时，取 digest 中下标为 0 ~ 3 的4个字节进行位运算
                        // h = 1 时，取 digest 中下标为 4 ~ 7 的4个字节进行位运算
                        // h = 2, h = 3 时过程同上
                        long m = hash(digest, h);
                        // 将 hash 到 address 的映射关系存储到 virtualServerNode 中，
                        // virtualInvokers 需要提供高效的查询操作，因此选用 TreeMap 作为存储结构
                        virtualServerNode.put(m, address);
                    }
                }
            }

        }
        /**
         * MD5的作用是让大容量信息在用数字签名软件签署私人密钥前被"压缩"成一种保密的格式，
         * 就是把一个任意长度的字节串变换成一定长的16进制字节串。
         * @param key
         * @return
         */
        static byte[] md5(String key) {
            MessageDigest md;
            try {
                md = MessageDigest.getInstance("MD5");
                byte[] bytes = key.getBytes(StandardCharsets.UTF_8);
                md.update(bytes);
            } catch (NoSuchAlgorithmException e) {
                throw new IllegalStateException(e.getMessage(), e);
            }

            return md.digest();
        }

        /**
         * digest: 16位 0xFF: 1111 1111
         * @param digest
         * @param number
         * @return
         */
        private long hash(byte[] digest, int number) {
            // 将这个 hash 投射到 [0, 2^32 - 1] 的圆环上，就是靠如下的移位实现的
            return (((long) (digest[3 + number * 4] & 0xFF) << 24)
                    | ((long) (digest[2 + number * 4] & 0xFF) << 16)
                    | ((long) (digest[1 + number * 4] & 0xFF) << 8)
                    | (digest[number * 4] & 0xFF))
                    & 0xFFFFFFFFL;
        }

        public String select(RpcRequestBody rpcRequestBody) {
            // 将参数转为 key
            String key = rpcRequestBody.getRequestId();
            // 对参数 key 进行 md5 运算
            byte[] digest = md5(key);
            // 取 digest 数组的前四个字节进行 hash 运算，再将 hash 值传给 selectForKey 方法，
            // 寻找合适的 Invoker
            return selectForKey(hash(digest, 0));
        }


        private String selectForKey(long hash) {
            // 到 TreeMap 中查找第一个节点值大于或等于当前 hash 的 Invoker
            Map.Entry<Long, String> entry = virtualServerNode.tailMap(hash, true).firstEntry();
            // 如果 hash 大于 Invoker 在圆环上最大的位置，此时 entry = null，
            // 需要将 TreeMap 的头节点赋值给 entry
            if (entry == null) {
                entry = virtualServerNode.firstEntry();
            }

            // 返回 Invoker
            return entry.getValue();
        }


    }
}

```

http://www.taodudu.cc/news/show-3644914.html?action=onClick

### Spring 自定义注解的实现

spring相关参考：https://juejin.cn/column/7140848085759950855

我们希望容器中创建的**每一个`bean`**，在创建的过程中可以执行一些自定义的逻辑，那么我们就可以编写一个类，并让他实现`BeanPostProcessor`接口，然后将这个类注册到一个容器中（@Compnent）：

```java
public interface BeanPostProcessor {
	// 注意这个方法名称关键的是before这个单词
	Object postProcessBeforeInitialization(Object bean, String beanName) 
        throws BeansException;

    // 注意这个方法名称关键的是after这个单词
	Object postProcessAfterInitialization(Object bean, String beanName) 
        throws BeansException;
}
```

那这两个方法何时执行呢？这就涉及到`Spring`中，`bean`的生命周期了:

![image-20230827140907615](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230827140907615.png)

`Spring`容器在创建`bean`时，如果容器中包含了`BeanPostProcessor`的实现类对象，那么就会执行这个类的这两个方法，并将当前正在创建的`bean`的引用以及名称作为参数传递进方法中。这也就是说，**`BeanPostProcessor`的作用域是当前容器中的所有`bean`** ，即容器中的所有在创建前后bean都会执行这两个方法，什么按是添加到容器，指的就是使用@Compnent和其他类似的注解的类。(其实也可以看作是一种代理)

我们可以在一个容器中注册多个不同的`BeanPostProcessor`的实现类对象，而`bean`在创建的过程中，将会轮流执行这些对象实现的`before`和`after`方法。

那执行顺序如何确定呢？`Spring`提供了一个接口`Ordered`，我们可以让`BeanPostProcessor`的**实现类实现**这个`Ordered`接口，并实现接口的`getOrder`方法。这个方法的返回值是一个`int`类型，`Spring`容器会通过这个方法的返回值，对容器中的多个`BeanPostProcessor`对象进行从小到大排序，然后在创建`bean`时依次执行它们的方法。也就是说，`getOrder`方法返回值越小的`BeanPostProcessor`对象，它的方法将越先被执行。

**限制：**

**BeanPostProcessor依赖的bean，不会执行BeanPostProcessor的方法**

当我们在`BeanPostProcessor`的实现类中，依赖了其他的`bean`，那么被依赖的`bean`被创建时，将不会执行它所在的`BeanPostProcessor`实现类实现的方法，比如我们修改`PostBean`的实现，如下所示：

```java
@Component
public class PostBean implements BeanPostProcessor, Ordered {
    // 让PostBean依赖User
    @Autowired
    private User user;

    @Override
    public Object postProcessBeforeInitialization(Object bean, String beanName) 
        throws BeansException {
        return bean;
    }

    @Override
    public Object postProcessAfterInitialization(Object bean, String beanName) 
        throws BeansException {
        return bean;
    }
}
```



此时，容器在创建`User`这个`bean`时，不会执行`PostBean`实现的两个方法，因为由于`PostBean`依赖于`user`，所以`user`需要在`PostBean`之前创建完成，这也就意味着在`user`创建时，`PostBean`还未初始化完成，所以不会调用它的方法。

**BeanPostProcessor以及依赖的bean无法使用AOP**

`Spring`的`AOP`代理就是作为`BeanPostProcessor`实现的，所以**我们无法对BeanPostProcessor的实现类使用AOP织入通知，也无法对BeanPostProcessor的实现类依赖的bean使用AOP织入通知**，例子：

```java
// PostBean 实现了 BeanPostProcessor，而User是 PostBean的依赖
@Component
public class PostBean implements BeanPostProcessor, Ordered {
    // 让PostBean依赖User
    @Autowired
    private User user;

    @Override
    public Object postProcessBeforeInitialization(Object bean, String beanName) 
        throws BeansException {
        return bean;
    }

    @Override
    public Object postProcessAfterInitialization(Object bean, String beanName) 
        throws BeansException {
        return bean;
    }

    // 此方法用来测试AOP，作为切点
    public void testAOP() {
        System.out.println("Post Bean");
    }
}

@Component
public class User {

    private String name;
    private int age;
	
    // ... 省略getter和setter...
    
    // 此方法用来测试AOP，用作切点
    public void testAOP() {
        System.out.println("user bean");
    }
}
```

```java
// 然后，我们定义一个AOP的切面，在切面中将PostBean的testAOP方法作为切点，代码如下：
@Aspect
public class BeanPostProcessorAspect {
    
	// 此方法织入PostBean的testAOP方法
    @Before("execution(* cn.tewuyiang.pojo.PostBean.testAOP(..))")
    public void before() {
        System.out.println("before1");
    }

    // 此方法织入User的testAOP方法
    @Before("execution(* cn.tewuyiang.pojo.User.testAOP(..))")
    public void before2() {
        System.out.println("before2");
    }
}
```

```java
// 测试
@Test
public void testConfig() {
    ApplicationContext context =
        new AnnotationConfigApplicationContext(AutoConfig.class);
    // 获取User这个bean，执行测试AOP的方法
    User user = context.getBean(User.class);
    user.testAOP();
    // 获取PostBean这个bean，执行测试AOP的方法
    PostBean bean = context.getBean(PostBean.class);
    bean.testAOP();
}

输出如下：
	user bean
	post Bean
```

**注册BeanPostProcessor的方式以及限制**

​       我们如何将`BeanPostProcessor`注册到`Spring`容器中？方式主要有两种，第一种就是上面一直在用的，将其声明在`Spring`的配置类或`xml`文件中，作为普通的`bean`，让`ApplicationContext`对象去加载它，这样它就被自动注册到容器中了。而且`Spring`容器会对`BeanPostProcessor`的实现类做特殊处理，即会将它们挑选出来，在加载其他`bean`前，优先加载`BeanPostProcessor`的实现类。

  还有另外一种方式就是使用`ConfigurableBeanFactory`接口的`addBeanPostProcessor`方法手动添加，`ApplicationContext`对象中组合了一个`ConfigurableBeanFactory`的实现类对象。但是这种方式添加`BeanPostProcessor`有一些缺点。首先，我们一创建`Spring`容器，在配置文件中配置的单例`bean`就会被加载，此时`addBeanPostProcessor`方法还没有执行，那我们手动添加的`BeanPostProcessor`也就无法作用于这些`bean`了，所以手动添加的`BeanPostProcessor`只能作用于那些延迟加载的`bean`，或者非单例`bean`。

​	还有一个就是，**使用addBeanPostProcessor方式添加的BeanPostProcessor，Ordered接口的作用将失效，而是以注册的顺序执行**。我们前面提过，`Ordered`接口用来指定多个`BeanPostProcessor`实现的方法的执行顺序。这是`Spring`官方文档中提到的：

While the recommended approach for `BeanPostProcessor` registration is through `ApplicationContext` auto-detection (as described above), it is also possible to register them programmatically against a `ConfigurableBeanFactory` using the `addBeanPostProcessor` method. This can be useful when needing to evaluate conditional logic before registration, or even for copying bean post processors across contexts in a hierarchy. Note however that `BeanPostProcessor` s added programmatically do not respect the `Ordered` interface. Here it is the order of registration that dictates the order of execution. Note also that `BeanPostProcessor` s registered programmatically are always processed before those registered through auto-detection, regardless of any explicit ordering.

**使用@Bean配置BeanPostProcessor的限制**

  如果我们使用`Java`类的方式配置`Spring`，并使用`@Bean`声明一个工厂方法返回`bean`实例，那么返回值的类型必须是`BeanPostProcessor`类型，或者等级低于`BeanPostProcessor`的类型。这里不好口头描述，直接看代码吧。以下是一个`BeanPostProcessor`的实现类，它实现了多个接口：

```java
/**
 * 此BeanPostProcessor的实现类，还实现了Ordered接口
 */
public class PostBean implements BeanPostProcessor, Ordered {

    @Override
    public Object postProcessBeforeInitialization(Object bean, String beanName) 
        throws BeansException {
        System.out.println("before -- " + beanName);
        return bean;
    }

    @Override
    public Object postProcessAfterInitialization(Object bean, String beanName) 
        throws BeansException {
        System.out.println("after -- " + beanName);
        return bean;
    }

    @Override
    public int getOrder() {
        return 0;
    }
}
```

我们在配置类中，声明`PostBean`可以有以下几种方式：

```java
@Configuration
public class BeanConfig {

	// 方式1：PostBean
    @Bean
    public PostBean postBean() {
        return new PostBean();
    }
    
    // 方式2：返回值为BeanPostProcessor
    @Bean
    public BeanPostProcessor postBean() {
        return new PostBean();
    }
    
    // 方式3：返回值为Ordered
    @Bean
    public Ordered postBean() {
        return new PostBean();
    }
}
```

以上三种方式都可以让`Spring`容器创建`PostBean`实例对象，因为`PostBean`实现了`BeanPostProcessor`和`Ordered`接口，所以它的对象也是这两种类型的对象。但是需要注意，上面三种方式中，只有第一种和第二种方式，会让`Spring`容器将`PostBean`当作`BeanPostProcessor`处理；而第三种方式，则会被当作一个普通`Bean`处理，实现`BeanPostProcessor`的两个方法都不会被调用。因为在`PostBean`的继承体系中，`Ordered`和`BeanPostProcessor`是同级别的，`Spring`无法识别出这个`Ordered`对象，也是一个`BeanPostProcessor`对象；但是使用`PostBean`却可以，因为`PostBean`类型就是`BeanPostProcessor`的子类型。**所以，在使用@Bean声明工厂方法返回BeanPostProcessor实现类对象时，返回值必须是BeanPostProcessor类型，或者更低级的类型**

分析这里的BeanPostProcessor

```java
@Slf4j
@Component
public class SpringBeanPostProcessor implements BeanPostProcessor {

    private final ServiceProvider serviceProvider;
    private final RpcRequestTransport rpcClient;

    public SpringBeanPostProcessor() {
        this.serviceProvider = SingletonFactory.getInstance(ZkServiceProviderImpl.class);
        this.rpcClient = ExtensionLoader.getExtensionLoader(RpcRequestTransport.class).getExtension(RpcRequestTransportEnum.NETTY.getName());
    }

    @SneakyThrows
    @Override
    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {
        // 
        if (bean.getClass().isAnnotationPresent(RpcService.class)) {
            log.info("[{}] is annotated with  [{}]", bean.getClass().getName(), RpcService.class.getCanonicalName());
            // get RpcService annotation
            RpcService rpcService = bean.getClass().getAnnotation(RpcService.class);
            // build RpcServiceProperties
            RpcServiceConfig rpcServiceConfig = RpcServiceConfig.builder()
                    .group(rpcService.group())
                    .version(rpcService.version())
                    .service(bean).build();
            serviceProvider.publishService(rpcServiceConfig);
        }
        return bean;
    }

    @Override
    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
        Class<?> targetClass = bean.getClass();
        Field[] declaredFields = targetClass.getDeclaredFields();
        for (Field declaredField : declaredFields) {
            RpcReference rpcReference = declaredField.getAnnotation(RpcReference.class);
            if (rpcReference != null) {
                RpcServiceConfig rpcServiceConfig = RpcServiceConfig.builder()
                        .group(rpcReference.group())
                        .version(rpcReference.version()).build();
                RpcClientProxy rpcClientProxy = new RpcClientProxy(rpcClient, rpcServiceConfig);
                Object clientProxy = rpcClientProxy.getProxy(declaredField.getType());
                declaredField.setAccessible(true);
                try {
                    declaredField.set(bean, clientProxy);
                } catch (IllegalAccessException e) {
                    e.printStackTrace();
                }
            }

        }
        return bean;
    }
}
```



ImportBeanDefinitionRegistrar

```java
public class CustomScannerRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware {
    private static final String SPRING_BEAN_BASE_PACKAGE = "github.javaguide";
    private static final String BASE_PACKAGE_ATTRIBUTE_NAME = "basePackage";
    private ResourceLoader resourceLoader;

    @Override
    public void setResourceLoader(ResourceLoader resourceLoader) {
        this.resourceLoader = resourceLoader;

    }

    @Override
    public void registerBeanDefinitions(AnnotationMetadata annotationMetadata, BeanDefinitionRegistry beanDefinitionRegistry) {
        //get the attributes and values of RpcScan annotation
        AnnotationAttributes rpcScanAnnotationAttributes = AnnotationAttributes.fromMap(annotationMetadata.getAnnotationAttributes(RpcScan.class.getName()));
        String[] rpcScanBasePackages = new String[0];
        if (rpcScanAnnotationAttributes != null) {
            // get the value of the basePackage property
            rpcScanBasePackages = rpcScanAnnotationAttributes.getStringArray(BASE_PACKAGE_ATTRIBUTE_NAME);
        }
        if (rpcScanBasePackages.length == 0) {
            rpcScanBasePackages = new String[]{((StandardAnnotationMetadata) annotationMetadata).getIntrospectedClass().getPackage().getName()};
        }
        // Scan the RpcService annotation
        CustomScanner rpcServiceScanner = new CustomScanner(beanDefinitionRegistry, RpcService.class);
        // Scan the Component annotation
        CustomScanner springBeanScanner = new CustomScanner(beanDefinitionRegistry, Component.class);
        if (resourceLoader != null) {
            rpcServiceScanner.setResourceLoader(resourceLoader);
            springBeanScanner.setResourceLoader(resourceLoader);
        }
        int springBeanAmount = springBeanScanner.scan(SPRING_BEAN_BASE_PACKAGE);
        log.info("springBeanScanner扫描的数量 [{}]", springBeanAmount);
        int rpcServiceCount = rpcServiceScanner.scan(rpcScanBasePackages);
        log.info("rpcServiceScanner扫描的数量 [{}]", rpcServiceCount);

    }

}
```



实现了两个接口

1. ResourceLoaderAware
2. ImportBeanDefinitionRegistrar

首先，关于第一个接口`Spring` `ResourceLoader`为我们提供了一个统一的`getResource()`方法来通过资源路径检索外部资源。

`Resource`是`Spring`中用于表示外部资源的通用接口。

```java
public interface Resource extends InputStreamSource {
    boolean exists();

    default boolean isReadable() {
        return this.exists();
    }

    default boolean isOpen() {
        return false;
    }

    default boolean isFile() {
        return false;
    }

    URL getURL() throws IOException;

    URI getURI() throws IOException;

    File getFile() throws IOException;

    default ReadableByteChannel readableChannel() throws IOException {
        return Channels.newChannel(this.getInputStream());
    }

    long contentLength() throws IOException;

    long lastModified() throws IOException;

    Resource createRelative(String var1) throws IOException;

    @Nullable
    String getFilename();

    String getDescription();
}
```

`Spring`为`Resource`接口提供了以下6种实现（以下的类都实现了Resource接口）。

1. `UrlResource`
2. `ClassPathResource`
3. `FileSystemResource`
4. `ServletContextResource`
5. `InputStreamResource`
6. `ByteArrayResource`

| `classpathResource`   | `classpath:com/myapp/config.xml` | 从类路径加载                     |
| --------------------- | -------------------------------- | -------------------------------- |
| `FileSystemResource:` | `file:///data/config.xml`        | 从文件系统作为`URL`加载。        |
| `UrlResource:`        | `https://myserver/logo.png`      | 从`URL`加载                      |
| `(none)`              | `/data/config.xml`               | 取决于底层的`ApplicationContext` |

**ResourceLoader**

它用于加载资源（例如类路径或文件系统资源）。它有两种方法：

```java
//Expose the ClassLoader used by this ResourceLoader.
ClassLoader getClassLoader()
 
//Return a Resource handle for the specified resource location.
Resource getResource(String location)
```

`getResource（）`方法将根据资源路径决定要实例化的`Resource`实现。 要获取`ResourceLoader`的引用，请实现`ResourceLoaderAware`接口。

```java
Resource banner = resourceLoader.getResource("file:c:/temp/filesystemdata.txt");
```

**使用`ResourceLoaderAware`加载资源**

为了演示下面的各种示例，我将一个具有相同名称的文件放置在不同的位置，并且我将演示如何加载每个文件。

```java
// CustomResourceLoader.java的编写如下，它将已加载的资源文件的内容打印到控制台中。
import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
 
import org.springframework.context.ResourceLoaderAware;
import org.springframework.core.io.Resource;
import org.springframework.core.io.ResourceLoader;
 
public class CustomResourceLoader implements ResourceLoaderAware
{
    private ResourceLoader resourceLoader;
 
    public void setResourceLoader(ResourceLoader resourceLoader) {
        this.resourceLoader = resourceLoader;
    }
 	
    public void showResourceData() throws IOException
    {
        //This line will be changed for all versions of other examples
        Resource banner = resourceLoader.getResource("file:c:/temp/filesystemdata.txt");
 
        InputStream in = banner.getInputStream();
 
        BufferedReader reader = new BufferedReader(new InputStreamReader(in));
 
        while (true) {
            String line = reader.readLine();
            if (line == null)
                break;
            System.out.println(line);
        }
        reader.close();
    }
}

// 该文件的applicationContext.xml文件条目如下：
// <bean id="customResourceLoader" class="cn.howtodoinjava.demo.CustomResourceLoader"></bean>

// 测试代码如下：
@SuppressWarnings("resource")
public static void main(String[] args) throws Exception
{
    ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml");
 
    CustomResourceLoader customResourceLoader = (CustomResourceLoader) context.getBean("customResourceLoader");
 
    customResourceLoader.showResourceData();
}

```

![image-20230827170345659](C:\Users\yangc\AppData\Roaming\Typora\typora-user-images\image-20230827170345659.png)

其余见：https://juejin.cn/post/6844903977637658637

 ResourceLoaderAware 只需要覆盖一个方法： public void setResourceLoader(ResourceLoader resourceLoader) ，而showResourceData()则是自定义的方法，实现这个接口应该是为了固定能够有调用的setResourceLoader方法。

**ImportBeanDefinitionRegistrar**

spring官方就是用这种方式，实现了`@Component`、`@Service`等注解的动态注入机制。定义一个ImportBeanDefinitionRegistrar的实现类，然后使用`@Import`导入，**spring会按照ImportBeanDefinitionRegistrar接口中的registerBeanDefinitions方法逻辑进行bean的注册**。

这里我们用一个简单的例子说明，我们需要实现类似`@Componet`的功能，添加了`@Mapper`注解的类会被自动加入到spring容器中。

```java
@Documented
@Inherited
@Retention(RetentionPolicy.RUNTIME)
@Target({ElementType.TYPE, ElementType.FIELD, ElementType.METHOD, ElementType.PARAMETER})
public @interface Mapper {
}

@Mapper
public class CountryMapper {
}
```

创建`MapperAutoConfiguredMyBatisRegistrar`实现`ImportBeanDefinitionRegistrar`，同时可以实现一些Aware接口，获得spring的一些数据(在我们的参考项目中的类中仅仅实现了BeanFactoryAware) 如：

- BeanFactoryAware
- ResourceLoaderAware
- EnvironmentAware
- ...

```java
public class MapperAutoConfigureRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware {
	
	private ResourceLoader resourceLoader;

	@Override
	public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {
		MapperBeanDefinitionScanner scanner = new MapperBeanDefinitionScanner(registry, false);
		scanner.setResourceLoader(resourceLoader);
		scanner.registerFilters();
		scanner.addIncludeFilter(new AnnotationTypeFilter(Mapper.class));
		scanner.doScan("com.secbro2.learn.mapper");
	}

	@Override
	public void setResourceLoader(ResourceLoader resourceLoader) {
		this.resourceLoader = resourceLoader;
	}
}
```

ImportBeanDefinitionRegistrar接口需要我们实现`registerBeanDefinitions`方法。但是有一个问题，我们并不知道需要register哪些bean。这里我们还需要借助一个类`ClassPathBeanDefinitionScanner`，也就是扫描器，通过扫描器获取我们需要注册的bean。先简单看一下spring源码中的的定义

A bean definition scanner that detects bean candidates on the `classpath`,  registering corresponding bean definitions with a given registry ( {`@code BeanFactory`}  or  {`@code ApplicationContext`} ). (ClassPathBeanDefinitionScanner是一个bean的定义扫描器，它能够扫描classpath上的潜在的类， 并在`BeanFactory`或`ApplicationContext`容器中注册对应的bean定义)

需要继承`ClassPathBeanDefinitionScanner`，扫描使用`@Mapper`的注解的类，`ClassPathBeanDefinitionScanner`又继承`ClassPathScanningCandidateComponentProvider`类，`ClassPathScanningCandidateComponentProvider`中有两个TypeFilter集合，includeFilters、excludeFilters。满足任意includeFilters会被加载，同样的满足任意excludeFilters不会被加载。

```java
public class MapperBeanDefinitionScanner extends ClassPathBeanDefinitionScanner {

	public MapperBeanDefinitionScanner(BeanDefinitionRegistry registry, boolean useDefaultFilters) {
		super(registry, useDefaultFilters);
	}

	protected void registerFilters() {
		addIncludeFilter(new AnnotationTypeFilter(Mapper.class));
	}

	@Override
	protected Set<BeanDefinitionHolder> doScan(String... basePackages) {
		return super.doScan(basePackages);
	}
}
```

应用：

```java
@Configuration
@Import(MapperAutoConfigureRegistrar.class)
public class MapperAutoConfig {
}
```

单元测试：

```java
@RunWith(SpringRunner.class)
@SpringBootTest
public class MapperAutoConfigureRegistrarTest {

	@Autowired
	UserMapper userMapper;

	@Test
	public void contextLoads() {
		System.out.println(userMapper.getClass());
	}
}
```

这个类中主要用于为相关的bean添加一些定制的动作，告诉spring加载这个bean的时候需要做些什么比如说扫描哪些包，扫描那些注解（@interface）

```java
@Target({ElementType.TYPE, ElementType.METHOD})
@Retention(RetentionPolicy.RUNTIME)
@Import(CustomScannerRegistrar.class)

// 如果一个注解@B，被@Documented标注，那么被@B修饰的类，
// 生成文档时，会显示@B。如果@B没有被@Documented标注，
// 最终生成的文档中就不会显示@B。这里的生成文档指的JavaDoc文档！
@Documented
public @interface RpcScan {

    String[] basePackage();

}

package github.javaguide.spring;

import github.javaguide.annotation.RpcScan;
import github.javaguide.annotation.RpcService;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.support.BeanDefinitionRegistry;
import org.springframework.context.ResourceLoaderAware;
import org.springframework.context.annotation.ImportBeanDefinitionRegistrar;
import org.springframework.core.annotation.AnnotationAttributes;
import org.springframework.core.io.Resource;
import org.springframework.core.io.ResourceLoader;
import org.springframework.core.type.AnnotationMetadata;
import org.springframework.core.type.StandardAnnotationMetadata;
import org.springframework.stereotype.Component;

/**
 * 这个类要求我们在加载有@RpcScan注解的bean的时候，扫描两种bean，一种是spring自带的Component，另一种是自定义的Service
 * compent通过SPRING_BEAN_BASE_PACKAGE 路径进行扫描。Service通过@RpcScan 注解中定义的String[] basePackage();传入的路径
 * 进行扫描
 */
@Slf4j
public class CustomScannerRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware {
    private static final String SPRING_BEAN_BASE_PACKAGE = "github.javaguide";
    private static final String BASE_PACKAGE_ATTRIBUTE_NAME = "basePackage";
    private ResourceLoader resourceLoader;

    @Override
    public void setResourceLoader(ResourceLoader resourceLoader) {
        this.resourceLoader = resourceLoader;

    }

    @Override
    public void registerBeanDefinitions(AnnotationMetadata annotationMetadata, BeanDefinitionRegistry beanDefinitionRegistry) {
        //get the attributes and values of RpcScan annotation
        AnnotationAttributes rpcScanAnnotationAttributes = AnnotationAttributes.fromMap(annotationMetadata.getAnnotationAttributes(RpcScan.class.getName()));
        String[] rpcScanBasePackages = new String[0];
        if (rpcScanAnnotationAttributes != null) {
            // get the value of the basePackage property
            rpcScanBasePackages = rpcScanAnnotationAttributes.getStringArray(BASE_PACKAGE_ATTRIBUTE_NAME);
        }
        if (rpcScanBasePackages.length == 0) {
            rpcScanBasePackages = new String[]{((StandardAnnotationMetadata) annotationMetadata).getIntrospectedClass().getPackage().getName()};
        }
        // Scan the RpcService annotation 实现 ClassPathBeanDefinitionScanner 接口
        // 第二个参数beanDefinitionRegistry 就传入了这里
        CustomScanner rpcServiceScanner = new CustomScanner(beanDefinitionRegistry, RpcService.class);
        // Scan the Component annotation 实现 ClassPathBeanDefinitionScanner 接口
        CustomScanner springBeanScanner = new CustomScanner(beanDefinitionRegistry, Component.class);

        if (resourceLoader != null) {
            rpcServiceScanner.setResourceLoader(resourceLoader);
            springBeanScanner.setResourceLoader(resourceLoader);
        }
       
        int rpcServiceCount = rpcServiceScanner.scan(rpcScanBasePackages);
        log.info("rpcServiceScanner扫描的数量 [{}]", rpcServiceCount);
        int springBeanAmount = springBeanScanner.scan(SPRING_BEAN_BASE_PACKAGE);
        log.info("springBeanScanner扫描的数量 [{}]", springBeanAmount);

    }

}
```

```java
public class CustomScanner extends ClassPathBeanDefinitionScanner {

    public CustomScanner(BeanDefinitionRegistry registry, Class<? extends Annotation> annoType) {
        super(registry);
        // addIncludeFilter添加一个加入的过滤器，用于扫描特定的类，需要传入Annotation类的子类的类对象
        // RpcService.class
        // `ClassPathScanningCandidateComponentProvider`中的两个TypeFilter集合，includeFilters、excludeFilters 之一。
        super.addIncludeFilter(new AnnotationTypeFilter(annoType));
    }

    @Override
    public int scan(String... basePackages) {
        return super.scan(basePackages);
    }
}
```

@Compnent 的类

**AnnotationMetadata**

```java
public interface AnnotationMetadata extends ClassMetadata, AnnotatedTypeMetadata {

	//拿到Class上标注的所有注解，依赖于Class#getAnnotations
	Set<String> getAnnotationTypes();

	// 拿到所有的元注解信息AnnotatedElementUtils#getMetaAnnotationTypes
	//annotationName:注解类型的全类名
	Set<String> getMetaAnnotationTypes(String annotationName);
	// 是否包含指定注解 （annotationName：全类名）
	boolean hasAnnotation(String annotationName);
	//这个厉害了，依赖于AnnotatedElementUtils#hasMetaAnnotationTypes
	boolean hasMetaAnnotation(String metaAnnotationName);
	// 类里面只有有一个方法标注有指定注解，就返回true
	//getDeclaredMethods获得所有方法， AnnotatedElementUtils.isAnnotated是否标注有指定注解
	boolean hasAnnotatedMethods(String annotationName);
	// 注意返回的是MethodMetadata 原理基本同上
	// .getDeclaredMethods和AnnotatedElementUtils.isAnnotated  最后吧Method转为MethodMetadata
	Set<MethodMetadata> getAnnotatedMethods(String annotationName);
}
```

```java
public interface AnnotatedTypeMetadata {

    // 根据“全类名”判断是否被指定 直接注解或元注解 标注
    boolean isAnnotated(String annotationName);
    
    // 根据”全类名“获取所有注解属性（包括元注解）
    @Nullable
    Map<String, Object> getAnnotationAttributes(String annotationName);
    
    @Nullable
    // 同上，但是第二个参数传 true 时会把属性中对应值为 Class 的值
    // 转为 字符串，避免需要预先加载对应 Class
    Map<String, Object> getAnnotationAttributes(String annotationName, boolean classValuesAsString);
    
    @Nullable
    // 同上，MultiValueMap 是一个 key 可以对应多个 value 的变种 map
    MultiValueMap<String, Object> getAllAnnotationAttributes(String annotationName);
    @Nullable
    MultiValueMap<String, Object> getAllAnnotationAttributes(String annotationName, boolean classValuesAsString);

}
```

AnnotationAttributes是为了存储注解属性或者信息的一个map数据结构，本身继承自linkedhashmap

详见：https://blog.csdn.net/awds18338701279/article/details/120875931

StandardAnnotationMetadata：https://blog.csdn.net/vistaed/article/details/108058157



### 单例模式



### 线程池

https://cloud.tencent.com/developer/article/2009034

线程池使用了自己编写的工具创建：

包含对共享资源的访问控制：

### 抽象出通信的方法

两个函数，从连接处获取一个对象，返回值为我们要处理的对象。另一个为将一个对象传递出去。

接受包括建立连接，分装对象

### 网络连接的方式

需要优化的点为：服务连接失败的场景

1。直接使用socket：这种方式的核心代码如下，首先是客户端

```java
  try (Socket socket = new Socket("localhost", 9000)) {
            // 发送对象
            ObjectOutputStream objectOutputStream = new ObjectOutputStream(socket.getOutputStream());
            ObjectInputStream objectInputStream = new ObjectInputStream(socket.getInputStream());
            objectOutputStream.writeObject(rpcRequest);
            objectOutputStream.flush();

            // 阻塞，等待responce
            RpcResponse rpcResponse = (RpcResponse) objectInputStream.readObject();

            return rpcResponse;

        } catch (IOException | ClassNotFoundException e) {
            e.printStackTrace();
            return null;
        }
```

其次是服务端：

```java
ServerSocket serverSocket = new ServerSocket(port))
System.out.println("server starting...");
Socket handleSocket;
while ((handleSocket = serverSocket.accept()) != null) {
	System.out.println("client connected, ip:" + handleSocket.getInetAddress());
    //新线程的执行
    threadPool.execute(new RpcServerWorker(handleSocket, registeredService));
}

ObjectInputStream objectInputStream = new ObjectInputStream(handleSocket.getInputStream());
ObjectOutputStream objectOutputStream = new ObjectOutputStream(handleSocket.getOutputStream());

// 接收对象
RpcRequest rpcRequest = (RpcRequest) objectInputStream.readObject();

// 发送对象
objectOutputStream.writeObject(rpcResponse);
objectOutputStream.flush();
```

这里在服务端我使用了线程池的方式对客户端信息进行监听。能够在处理多个客户端信息的情况下，还能够降低线程的创建回收成本，指定创建的最大线程数目，防止资源被浪费。

```java
 public RpcServer() {

        int corePoolSize = 5;
        int maximumPoolSize = 50;
        long keepAliveTime = 60;

        BlockingQueue<Runnable> workingQueue = new ArrayBlockingQueue<>(100);

        ThreadFactory threadFactory = Executors.defaultThreadFactory();

        this.threadPool = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, TimeUnit.SECONDS, workingQueue, threadFactory);

        this.registeredService = new HashMap<String, Object>();
    }

// 配合上面的
threadPool.execute(new RpcServerWorker(handleSocket, registeredService));
```

对于java_guide_pcr：代码的解析

首先是客户端：在客户端中首先获得两个对象：

```java
RpcRequestTransport rpcRequestTransport = new SocketRpcClient();
RpcServiceConfig rpcServiceConfig = new RpcServiceConfig();
```

这两个对象分别是服务器对象和服务器设置对象（其中存了一些服务器的相关设置信息）与注册中心的通信就放在服务器对象中。接下来将两个对象传入RpcClientProxy，这个类为代理对象类，将要为之后传入的class提供代理类，通过代理类连接服务器，以达到rpc远程调用的效果

```java
RpcClientProxy rpcClientProxy = new RpcClientProxy(rpcRequestTransport, rpcServiceConfig);
```

传入的class 还是通过手动传入的，以下为获取代理对象的代码，该行通过传入HellowService.class来获得HellowService的代理类。

```java
HelloService helloService = rpcClientProxy.getProxy(HelloService.class);
```

在代理类中通过反射机制获取原类的各种信息构建rpcRequest，并通过调用sendRpcRequest方法与服务器进行通信：

```java
 rpcResponse = (RpcResponse<Object>) rpcRequestTransport.sendRpcRequest(rpcRequest);
```

以上为socket方式，使用Netty方式会使用CompletableFuture接受结果。服务器对象中存在一个注册中心的类serviceDiscovery，serviceDiscovery 的获取方式如下，这个获取方式是SPI的方式。

```java
this.serviceDiscovery = ExtensionLoader.getExtensionLoader(ServiceDiscovery.class).getExtension(ServiceDiscoveryEnum.ZK.getName());
// 通过lookup方式找到提供rpcRequest中要求的方法的服务器，并将服务器的地址以及端口打包成 InetSocketAddress返回
InetSocketAddress inetSocketAddress = serviceDiscovery.lookupService(rpcRequest);

//lookup方法的接口
InetSocketAddress lookupService(RpcRequest rpcRequest);
```

返回的是InetSocketAddress， InetSocketAddress类主要作用是封装端口和ip地址。



对于服务端的修改：

首先服务器测试的阶段应该隐藏新建代理等工作，测试只需要获得服务器对象，要求服务，获得对应对象，使用对象即可。

在服务器端，原本需要通过如下代码注册服务器提供的服务。这一步本来是给注册中心进行注册的，而客户端也是从注册中心拿到提供相应的功能的服务器的ip地址的。

```java
HelloService helloService = new HelloServiceImpl(); // 包含需要处理的方法的对象
rpcServer.register(helloService); // 向rpc server注册对象里面的所有方法
```



## python调用jar字典类型

要在Python中调用Java中的字典类型（也称为Map类型），可以使用Java虚拟机的Python接口——JPype。以下是一些简单的步骤，可以在Python中使用Java的字典类型：

首先，请确保已安装JPype。可以使用以下命令在命令行中安装JPype：

```
pip install JPype1
```

然后，需要导入JPype包和Java类。假设要调用Java中的HashMap类，可以使用以下代码导入：

```python
import jpype
from jpype import java
HashMap = jpype.JClass('java.util.HashMap')
```

创建一个HashMap实例：

```python
my_map = HashMap()
```

将键值对添加到HashMap中：

```python
my_map.put("key1", "value1")
my_map.put("key2", "value2")
```

使用如下代码对键值进行检索：

```python
value = my_map.get("key1")
```

最后，使用以下代码关闭Java虚拟机：

```python
jpype.shutdownJVM()
```

